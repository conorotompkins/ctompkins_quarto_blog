[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a data scientist in the Pittsburgh area with an interest in data visualization, statistical programming, birdwatching, and civic data."
  },
  {
    "objectID": "posts/suburbanization-of-allegheny-county/index.html",
    "href": "posts/suburbanization-of-allegheny-county/index.html",
    "title": "Suburbanization of Allegheny County",
    "section": "",
    "text": "This March, researchers at the University of Georgia and Florida State University released the HHUUD10 dataset, which contains estimates of the number of housing units for decennial census years 1940-2010 and 2019. A “housing unit” could be a studio apartment or 5 bedroom single-family home. The data uses 2010 census tracts, which allows for historical comparison of housing trends across constant geometry. The full paper explains the approach.\nThis paper and the dataset can be used for a wide variety of socioeconomic issues. I will focus on suburbanization trends in the Pittsburgh area."
  },
  {
    "objectID": "posts/suburbanization-of-allegheny-county/index.html#overall-trend",
    "href": "posts/suburbanization-of-allegheny-county/index.html#overall-trend",
    "title": "Suburbanization of Allegheny County",
    "section": "Overall trend",
    "text": "Overall trend\n\nFix date formatting\nSince the data comes in a wide format, I pivot it long and fix up the year column to make it easy to graph with.\n\nac_housing_hu &lt;- ac_housing |&gt; \n  select(GEOID10, starts_with(\"hu\")) |&gt; \n  pivot_longer(cols = starts_with(\"hu\"), names_to = \"year\", values_to = \"housing_units\")\n\nyear_lookup &lt;- ac_housing_hu |&gt; \n  st_drop_geometry() |&gt; \n  distinct(year) |&gt; \n  mutate(year_fixed = c(1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2019))\n\nac_housing_hu &lt;- ac_housing_hu |&gt; \n  left_join(year_lookup) |&gt; \n  select(-year) |&gt; \n  rename(year = year_fixed)\n\nglimpse(ac_housing_hu)\n\nRows: 3,618\nColumns: 4\n$ GEOID10       &lt;chr&gt; \"42003560500\", \"42003560500\", \"42003560500\", \"4200356050…\n$ geometry      &lt;POLYGON [US_survey_foot]&gt; POLYGON ((1373906 410182, 1..., POL…\n$ housing_units &lt;dbl&gt; 1349, 1509, 1515, 1441, 1424, 1433, 1381, 1349, 1487, 13…\n$ year          &lt;dbl&gt; 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2019, 19…\n\n\nThe number of housing units in the county stagnated after 1960, which is expected given the collapse of the steel industry.\n\nac_housing_hu |&gt; \n  st_drop_geometry() |&gt; \n  mutate(year = as.character(year) |&gt; fct_inorder()) |&gt; \n  group_by(year) |&gt; \n  summarize(housing_units = sum(housing_units)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(year, housing_units, group = 1)) +\n  geom_line() +\n  geom_point() +\n  scale_y_comma() +\n  labs(x = \"Year\",\n       y  = \"Housing units\")\n\n\n\n\nThe decennial difference in “gross” housing units also shows that growth stagnated after 1960.\n\nac_housing_hu |&gt; \n  st_drop_geometry() |&gt; \n  mutate(year = as.character(year) |&gt; fct_inorder()) |&gt; \n  group_by(year) |&gt; \n  summarize(housing_units = sum(housing_units)) |&gt; \n  ungroup() |&gt; \n  mutate(diff = housing_units - lag(housing_units)) |&gt; \n  ggplot(aes(year, diff, group = 1)) +\n  geom_line() +\n  geom_point() +\n  scale_y_comma(prefix = \"+ \") +\n  coord_cartesian(ylim = c(0, 90000)) +\n  labs(title = \"Growth stagnated after 1960\",\n       x = \"Year\",\n       y  = \"Change in housing units\")"
  },
  {
    "objectID": "posts/suburbanization-of-allegheny-county/index.html#change-from-1940-to-2019",
    "href": "posts/suburbanization-of-allegheny-county/index.html#change-from-1940-to-2019",
    "title": "Suburbanization of Allegheny County",
    "section": "Change from 1940 to 2019",
    "text": "Change from 1940 to 2019\nThis interactive map shows the areas that gained or lost the most housing units from 1940-2019. Dense housing around industrial areas along the Allegheny and Monongahela Rivers was erased. Homestead and Braddock stand out.\n\nhu_diff &lt;- ac_housing_hu |&gt; \n  group_by(GEOID10) |&gt; \n  filter(year == min(year) | year == max(year)) |&gt; \n  ungroup() |&gt; \n  select(GEOID10, year, housing_units) |&gt; \n  as_tibble() |&gt; \n  pivot_wider(names_from = year, names_prefix = \"units_\", values_from = housing_units) |&gt; \n  mutate(diff = units_2019 - units_1940) |&gt; \n  st_as_sf()\n\npal &lt;- colorNumeric(\n  palette = \"viridis\",\n  domain = hu_diff$diff)\n\nleaflet_map &lt;- hu_diff |&gt; \n  mutate(diff_formatted = comma(diff, accuracy = 1),\n         diff_label = str_c(\"Census tract: \", GEOID10, \"&lt;br/&gt;\", \"Difference: \", diff_formatted)) |&gt; \n  st_transform(crs = 4326) |&gt; \n  leaflet() |&gt; \n  setView(lat = 40.441606, lng = -80.010957, zoom = 10) |&gt; \n  addProviderTiles(providers$Stamen.TonerLite,\n                   options = providerTileOptions(noWrap = TRUE,\n                                                 minZoom = 9),\n                   group = \"Base map\") |&gt; \n  addPolygons(popup = ~ diff_label,\n              fillColor = ~pal(diff),\n              fillOpacity = .7,\n              color = \"black\",\n              weight = 1,\n              group = \"Housing\") |&gt; \n  addLegend(\"bottomright\", pal = pal, values = ~diff,\n            title = \"Difference\",\n            opacity = 1) |&gt; \n  addLayersControl(overlayGroups = c(\"Base map\", \"Housing\"),\n                   options = layersControlOptions(collapsed = FALSE)) |&gt; \n  addFullscreenControl()\n\nleaflet_map\n\n\n\n\n#frameWidget(leaflet_map, options=frameOptions(allowfullscreen = TRUE))\n\nThe North Side and the Hill were targets of “urban renewal” in the middle of the century. Dense housing in heavily African-American communities were demolished to make way for an opera house, the 279 and 579 highways, and parking lots. The highways are directly related to the white flight exodus to the suburbs, especially in the west and north. Those highways made it easy for the new suburbanites to commute longer distances in single passenger vehicles.\nThese graphs shows that the areas with the most housing in 1940 lost thousands of units, while outlying areas gained thousands of units.\n\nslope_graph_anim &lt;- hu_diff |&gt; \n  as_tibble() |&gt; \n  select(-geometry) |&gt;\n  arrange(desc(units_1940)) |&gt; \n  pivot_longer(cols = c(units_1940, units_2019), names_to = \"year\", values_to = \"housing_units\") |&gt; \n  mutate(year = str_remove(year, \"^units_\")) |&gt; \n  mutate(order = row_number()) |&gt; \n  ggplot(aes(year, housing_units)) +\n  geom_line(aes(group = GEOID10), alpha = .1) +\n  geom_point(aes(group = str_c(year, GEOID10)), alpha = .05) +\n  scale_y_comma() +\n  transition_reveal(order) +\n  labs(title = \"Housing unit change from 1940-2019\",\n       subtitle = \"From areas with the most units in 1940 to the least\",\n       x = \"Year\",\n       y = \"Housing units\") +\n  theme(panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.border = element_blank(),\n        axis.title.x = element_blank())\n\nslope_graph_anim &lt;- animate(slope_graph_anim, duration = 10, fps = 40, end_pause = 60)\n\nslope_graph_anim\n\n\n\n\n\nhu_diff |&gt; \n  ggplot(aes(units_1940, units_2019)) +\n  geom_abline(lty = 2) +\n  geom_point(alpha = .2) +\n  annotate(\"text\", x = 3500, y = 3800, label = \"No change\", angle = 45) +\n  annotate(\"text\", x = 300, y = 4500, label = \"Gain\") +\n  annotate(\"text\", x = 4300, y = 100, label = \"Loss\") +\n  tune::coord_obs_pred() +\n  scale_x_comma() +\n  scale_y_comma() +\n  labs(title = \"Change in housing units\",\n       x = \"Units in 1940\",\n       y = \"Units in 2019\")\n\n\n\n\n\nMoving north and west\nThese maps show the estimates of housing units for each decennial period. Outlying areas in the north and west, directly served by the new highway system, gained thousands of housing units.\n\nac_housing_hu |&gt; \n  ggplot() +\n  geom_sf(aes(fill = housing_units), color = NA) +\n  scale_fill_viridis_c(\"Housing units\", labels = comma) +\n  facet_wrap(~year) +\n  theme_bw() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank())\n\n\n\n\nGeographically larger Census tracts gained more of the % of total housing over time.\n\nac_sqmi &lt;- ac_housing |&gt; \n  select(GEOID10, starts_with(\"sqmi\")) |&gt; \n  st_drop_geometry() |&gt; \n  as_tibble() |&gt; \n  pivot_longer(starts_with(\"sqmi\"), names_to = \"year\", values_to = \"sqmi\")\n\nac_sqmi_year &lt;- ac_sqmi |&gt; \n  distinct(year) |&gt; \n  mutate(year_fixed = c(1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2019))\n\nac_sqmi &lt;- ac_sqmi |&gt; \n  left_join(ac_sqmi_year) |&gt; \n  select(-year) |&gt; \n  rename(year = year_fixed)\n\nac_density &lt;- ac_housing_hu |&gt; \n  select(GEOID10, year, housing_units) |&gt; \n  left_join(ac_sqmi) |&gt; \n  mutate(density = housing_units / sqmi)\n\ncurve_anim &lt;- ac_density |&gt; \n  st_drop_geometry() |&gt; \n  select(GEOID10, year, housing_units, sqmi) |&gt; \n  mutate(year = as.character(year) |&gt; fct_inorder()) |&gt; \n  arrange(year, sqmi) |&gt; \n  group_by(year) |&gt; \n  mutate(housing_units_cumsum = cumsum(housing_units),\n         pct_units = housing_units_cumsum / sum(housing_units)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(sqmi, pct_units, color = year)) +\n  geom_line() +\n  scale_y_percent() +\n  labs(title = \"Housing moves to outlying areas over time\",\n       subtitle = \"Year: {closest_state}\",\n       x = \"Square miles\",\n       y = \"Cumulative percent of units\",\n       color = \"Year\") +\n  transition_states(year) +\n  shadow_mark()\n\ncurve_anim &lt;- animate(curve_anim, duration = 10, fps = 20)\n\ncurve_anim\n\n\n\n\n\n\nHousing peaks\nThis shows the year that each census tract peaked in terms of housing units. The areas that attracted heavy industry in the late 19th/early 20th century (and built housing nearby to support it) were crushed by the collapse of that industry. The single census tract that makes up “Downtown” has clawed back some housing recently.\n\nac_housing_hu |&gt; \n  group_by(GEOID10) |&gt; \n  filter(housing_units == max(housing_units)) |&gt; \n  ungroup() |&gt; \n  rename(max_year = year) |&gt; \n  ggplot() +\n  geom_sf(aes(fill = max_year), color = NA) +\n  scale_fill_viridis_c(direction = -1) +\n  labs(title = \"Year of peak housing\",\n       fill = \"Peak\") +\n  theme(panel.grid.major = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank(),\n        panel.border = element_blank())"
  },
  {
    "objectID": "posts/suburbanization-of-allegheny-county/index.html#housing-moves-away-from-the-center",
    "href": "posts/suburbanization-of-allegheny-county/index.html#housing-moves-away-from-the-center",
    "title": "Suburbanization of Allegheny County",
    "section": "Housing moves away from the center",
    "text": "Housing moves away from the center\nA major trend from 1940-2019 is the significant shift in housing from around the core to outlying suburbs. This code calculates the distance between each tract and the “Downtown” tract (42003020100), and plots the number of units compared to that distance.\n\ndowntown_tract &lt;- ac_housing_hu |&gt; \n  filter(GEOID10 == \"42003020100\") |&gt; \n  distinct(GEOID10, geometry) |&gt; \n  mutate(centroid = st_point_on_surface(geometry)) |&gt; \n  st_set_geometry(\"centroid\") |&gt; \n  select(-geometry)\n\ndistance_anim &lt;- ac_housing_hu |&gt; \n  select(GEOID10, year, housing_units) |&gt; \n  mutate(centroid = st_point_on_surface(geometry),\n         geoid = str_c(GEOID10, year, sep = \"_\"),\n         year = as.integer(year)) |&gt; \n  mutate(distance_to_downtown = st_distance(centroid, downtown_tract) |&gt; as.numeric() / 5280) |&gt; \n  ggplot(aes(distance_to_downtown, housing_units)) +\n  geom_point(aes(group = GEOID10), alpha = .3) +\n  geom_smooth(aes(group = year)) +\n  scale_x_continuous() +\n  scale_y_comma() +\n  transition_states(year, \n                    state_length = 10) +\n  labs(title = \"Housing has moved farther away from downtown\",\n       subtitle = \"{closest_state}\",\n       x = \"Miles from downtown\",\n       y = \"Housing units\") +\n  theme(panel.grid.minor = element_blank())\n\ndistance_anim &lt;- animate(distance_anim)\n\ndistance_anim"
  },
  {
    "objectID": "posts/suburbanization-of-allegheny-county/index.html#land-use",
    "href": "posts/suburbanization-of-allegheny-county/index.html#land-use",
    "title": "Suburbanization of Allegheny County",
    "section": "Land use",
    "text": "Land use\nThe HHUUD10 data also contains estimates for the percentage of land in a tract that is “developed” for the years 1992, 2001, and 2011. “Developed” in this context means “covered by an urban land use”.\n\nac_dev &lt;- ac_housing |&gt; \n  select(GEOID10, starts_with(\"pdev\")) |&gt; \n  pivot_longer(cols = starts_with(\"pdev\"), names_to = \"year\", values_to = \"pct_dev\") \n\ndev_years &lt;- ac_dev |&gt; \n  st_drop_geometry() |&gt; \n  distinct(year) |&gt; \n  mutate(year_fixed = c(1992, 2001, 2011))\n\nac_dev &lt;- ac_dev |&gt; \n  left_join(dev_years) |&gt; \n  select(-year) |&gt; \n  rename(year = year_fixed)\n\nac_dev |&gt; \n  ggplot() +\n  geom_sf(aes(fill = pct_dev), color = NA) +\n  facet_wrap(~year) +\n  scale_fill_viridis_c(labels = percent) +\n  labs(title = \"Percent of land that is developed\",\n       fill = NULL) +\n  theme_bw() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank())\n\n\n\n\nI find it interesting that more of the South Hills is developed than the North Hills. I would have expected more development in the North Hills due to the McKnight Road area and Wexford. My guess is that the tracts in the North Hills cover more land area, which decreases the % that is developed. Conversely, the tracts in the South Hills cover less land area, and less of the South Hills is useful for development because of steep hills and creeks. This concentrates development in a smaller area."
  },
  {
    "objectID": "posts/suburbanization-of-allegheny-county/index.html#conclusion",
    "href": "posts/suburbanization-of-allegheny-county/index.html#conclusion",
    "title": "Suburbanization of Allegheny County",
    "section": "Conclusion",
    "text": "Conclusion\nOver the past 80 years, Allegheny County has lost a significant amount of housing in its core urban area. Much of this is directly related to the collapse of the steel industry and “urban renewal”. At the same time, new housing development has been pushed out to the suburbs. This is a loss in terms of housing density, which has become a major discussion point in urban planning over the past 20 years.\nHigher density areas have a lower per capita carbon footprint due to non-car commute modes and agglomeration effects. Higher density also does not expand the wildland-urban interface. This leaves more land for the natural environment, moves humans away from dangers such as wildfires, and lowers the frequency of interaction between wild animals and humans, which can transfer disease (coronavirus, ebola). It will be interesting to see whether the suburbanization trend continues after the initial shocks of COVID-19 pandemic subside."
  },
  {
    "objectID": "posts/shifting_political_winds/index.html",
    "href": "posts/shifting_political_winds/index.html",
    "title": "Shifting political winds",
    "section": "",
    "text": "The purpose of this post is to recreate the “Shift from 2016” arrow map that the New York Times used to show which counties became more Democratic or Republican-leaning from 2016 to 2020. This is a screenshot of the NYTimes figure:\nI will use county-level Presidential election data from the MIT Election Data + Science Lab to recreate the chart. Since 2020 results are not final yet, I will focus on data from 2000-2016. I ran into multiple issues with the dataset, which I explain in the Code section below. The most signifcant issue was with the data from Alaska, which I excluded from the charts below because of problems with the data."
  },
  {
    "objectID": "posts/shifting_political_winds/index.html#recreating-the-nytimes-figure",
    "href": "posts/shifting_political_winds/index.html#recreating-the-nytimes-figure",
    "title": "Shifting political winds",
    "section": "Recreating the NYTimes Figure",
    "text": "Recreating the NYTimes Figure\nMy approach is to use {ggplot2} and {sf} to map the data and draw arrows at angles to display shifts in the Democratic margin.\nThis is the dataframe I use to make the final map. It contains the year, state, county, FIPS code, county and state geometries, and election results per county.\n\nglimpse(shift_map)\n\nRows: 12,610\nColumns: 22\n$ year                          &lt;dbl&gt; 2004, 2008, 2012, 2016, 2004, 2008, 2012…\n$ state                         &lt;chr&gt; \"ALABAMA\", \"ALABAMA\", \"ALABAMA\", \"ALABAM…\n$ county_name                   &lt;chr&gt; \"AUTAUGA\", \"AUTAUGA\", \"AUTAUGA\", \"AUTAUG…\n$ county_fips                   &lt;chr&gt; \"01001\", \"01001\", \"01001\", \"01001\", \"010…\n$ candidatevotes_sum_democrat   &lt;dbl&gt; 4758, 6093, 6363, 5936, 15599, 19386, 18…\n$ candidatevotes_sum_republican &lt;dbl&gt; 15196, 17403, 17379, 18172, 52971, 61271…\n$ pct_vote_democrat             &lt;dbl&gt; 0.23845, 0.25932, 0.26801, 0.24623, 0.22…\n$ pct_vote_republican           &lt;dbl&gt; 0.7616, 0.7407, 0.7320, 0.7538, 0.7725, …\n$ dem_margin_pct                &lt;dbl&gt; -0.52310, -0.48136, -0.46399, -0.50755, …\n$ dem_margin_votes              &lt;dbl&gt; -10438, -11310, -11016, -12236, -37372, …\n$ shift_pct                     &lt;dbl&gt; -0.106746, 0.041745, 0.017371, -0.043561…\n$ shift_votes                   &lt;dbl&gt; -3387, -872, 294, -1220, -10497, -4513, …\n$ shift_pct_scaled              &lt;dbl&gt; 71.83, 91.08, 87.92, 80.02, 78.51, 89.01…\n$ shift_votes_scaled            &lt;dbl&gt; 16602, 11700, 10573, 12378, 30460, 18796…\n$ shift_pct_binary              &lt;chr&gt; \"Republican\", \"Democratic\", \"Democratic\"…\n$ shift_votes_binned            &lt;lgl&gt; FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, F…\n$ geometry                      &lt;POLYGON [m]&gt; POLYGON ((1269841 -1303980,..., …\n$ center                        &lt;list&gt; &lt;POINT (1253837 -1285138)&gt;, &lt;POINT (125…\n$ lng0                          &lt;dbl&gt; 1253837, 1253837, 1253837, 1253837, 1177…\n$ lat0                          &lt;dbl&gt; -1285138, -1285138, -1285138, -1285138, …\n$ lng1                          &lt;dbl&gt; 1259015, 1253616, 1254221, 1255982, 1183…\n$ lat1                          &lt;dbl&gt; -1269365, -1273441, -1274572, -1272948, …\n\n\n\nshift_map_filtered &lt;- shift_map %&gt;% \n  filter(state != \"ALASKA\") %&gt;%\n  filter(year == 2016) %&gt;% \n  mutate(shift_pct_binary = case_when(sign(shift_pct) == 1 ~ \"Democratic\",\n                                      sign(shift_pct) == -1 ~ \"Republican\"),\n         shift_pct_binary = as.factor(shift_pct_binary)) %&gt;% \n  mutate(shift_votes_binned = abs(shift_votes) &lt;= 3000)\n\nggplot() +\n  geom_sf(data = filter(state_geo, !str_detect(NAME, \"ALASKA\")),\n          linewidth = .2,\n          fill = NA) +\n  geom_point(data = filter(shift_map_filtered, abs(shift_votes) &lt;= 1500),\n             aes(x = lng0, y = lat0,\n                 color = shift_pct_binary),\n             size = .75,\n             alpha = .3) +\n  geom_segment(data = filter(shift_map_filtered, abs(shift_votes) &gt; 1500),\n               aes(x = lng0, xend = lng1,\n                   y = lat0, yend = lat1,\n                   color = shift_pct_binary,\n                   linewidth = shift_votes,\n                   alpha = shift_votes_binned),\n               linejoin = \"mitre\",\n               arrow = arrow(length = unit(0.08, \"inches\"))) +\n  scale_color_manual(values = c(\"#1375B7\", \"#C93135\"), guide = guide_legend(title.position = \"top\")) +\n  scale_linewidth_continuous(range = c(.001, 2), guide = \"none\") +\n  scale_alpha_manual(values = c(1, .3), guide = \"none\") +\n  labs(color = \"Shift in election margin\") +\n  facet_wrap(~year) +\n  theme_void(base_size = 25) +\n  theme(legend.direction = \"horizontal\",\n        legend.position = \"bottom\")\n\n\n\n\nThe starting point of the line is the centroid of the county. The length and width of the lines are scaled to the shift in terms of number of votes. The NYTimes figure treats the shift as a binary variable when it rescales to degrees of the angle. In their graph, a Democratic shift is about 45 degrees (diagonal left) and a Republican shift is about 135 degrees (diagonal right). My figure maintains the continuous nature of the shift in %. I use the range 0-180 in degrees to indicate the shift. 0 degrees (all the way left) indicates a 100% shift towards Democrats, 90 degrees (pointing upwards) indicates no change, and 180 degrees (all the way to the right) indicates a 100% shift towards Republicans.\nThe end point of the line is calculated using the sine and cosine of the margin shift in % (re-scaled to be interpreted as degrees of an angle) multiplied by the margin shift in votes (re-scaled to be interpreted as meters), which is added to the origin point.\nI lower the opacity of the lines in counties where the vote totals did not shift much. I use points instead of lines for counties where there was a very small shift in votes. This prevents overplotting in geographically dense areas with small populations.\nThis animation shows the shift in Presidential election margin from 2004-2016.\n\npolitical_winds_anim &lt;- shift_map %&gt;% \n  filter(state != \"ALASKA\") %&gt;% \n  mutate(id = str_c(state, county_name, county_fips)) %&gt;% \n  mutate(year = as.integer(year)) %&gt;% \n  mutate(shift_pct_binary = case_when(sign(shift_pct) == 1 ~ \"Democratic\",\n                                      sign(shift_pct) == -1 ~ \"Republican\"),\n         shift_pct_binary = as.factor(shift_pct_binary)) %&gt;% \n  mutate(shift_votes_binned = abs(shift_votes) &lt;= 3000) %&gt;% \n  ggplot() +\n  geom_sf(data = filter(state_geo, NAME != \"ALASKA\"),\n          linewidth = .2,\n          fill = NA) +\n  geom_segment(aes(x = lng0, xend = lng1,\n                   y = lat0, yend = lat1,\n                   color = shift_pct_binary,\n                   linewidth = shift_votes,\n                   alpha = shift_votes_binned,\n                   group = id),\n               linejoin = \"mitre\",\n               arrow = arrow(length = unit(0.09, \"inches\"))) +\n  scale_color_manual(values = c(\"#1375B7\", \"#C93135\"), guide = guide_legend(title.position = \"top\")) +\n  scale_linewidth_continuous(range = c(.001, 1.3), guide = \"none\") +\n  scale_alpha_manual(values = c(1, .3), guide = \"none\") +\n  theme_void(base_size = 25) +\n  theme(legend.direction = \"horizontal\",\n        legend.position = \"bottom\") +\n  transition_states(year) +\n  labs(title = \"Shift in Presidential election Democratic margin\",\n       subtitle = \"Year: {closest_state}\",\n       color = \"Shift in Democratic margin\")\n\npolitical_winds_anim\n\n\n\n\nIn the animation there is less overplotting, so I do not replace lines with dots for counties where there was a very small shift in votes."
  },
  {
    "objectID": "posts/shifting_political_winds/index.html#code",
    "href": "posts/shifting_political_winds/index.html#code",
    "title": "Shifting political winds",
    "section": "Code",
    "text": "Code\n\nIngest\n\n#election shift\n#script to clean data\n\n#data from https://electionlab.mit.edu/data\n\n#fips info\n#https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code#FIPS_state_codes\n#https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county\n#changes https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.2010.html\n\n#read in data\ndata &lt;- read_csv(\"post_data/countypres_2000-2020.csv\",\n                 col_types = cols(\n                   year = col_double(),\n                   state = col_character(),\n                   state_po = col_character(),\n                   county_name = col_character(),\n                   county_fips = col_character(),\n                   office = col_character(),\n                   candidate = col_character(),\n                   party = col_character(),\n                   candidatevotes = col_double(),\n                   totalvotes = col_double(),\n                   version = col_double()\n                 )) %&gt;% \n  clean_names() |&gt;\n  filter(year &lt;= 2016,\n         mode == \"TOTAL\") |&gt; \n  select(-mode)\n\nglimpse(data)\n\nRows: 50,524\nColumns: 11\n$ year           &lt;dbl&gt; 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2…\n$ state          &lt;chr&gt; \"ALABAMA\", \"ALABAMA\", \"ALABAMA\", \"ALABAMA\", \"ALABAMA\", …\n$ state_po       &lt;chr&gt; \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"…\n$ county_name    &lt;chr&gt; \"AUTAUGA\", \"AUTAUGA\", \"AUTAUGA\", \"AUTAUGA\", \"BALDWIN\", …\n$ county_fips    &lt;chr&gt; \"01001\", \"01001\", \"01001\", \"01001\", \"01003\", \"01003\", \"…\n$ office         &lt;chr&gt; \"US PRESIDENT\", \"US PRESIDENT\", \"US PRESIDENT\", \"US PRE…\n$ candidate      &lt;chr&gt; \"AL GORE\", \"GEORGE W. BUSH\", \"RALPH NADER\", \"OTHER\", \"A…\n$ party          &lt;chr&gt; \"DEMOCRAT\", \"REPUBLICAN\", \"GREEN\", \"OTHER\", \"DEMOCRAT\",…\n$ candidatevotes &lt;dbl&gt; 4942, 11993, 160, 113, 13997, 40872, 1033, 578, 5188, 5…\n$ totalvotes     &lt;dbl&gt; 17208, 17208, 17208, 17208, 56480, 56480, 56480, 56480,…\n$ version        &lt;dbl&gt; 20220315, 20220315, 20220315, 20220315, 20220315, 20220…\n\n\n\n\nClean\nThis code filters out state-wide vote tabulations and then filters only on the two-party Presidential vote.\n\ndata &lt;- data %&gt;% \n  rename(fips_raw = county_fips) %&gt;% \n  #filter out state-wide ballot collection\n  filter(!(state == \"CONNECTICUT\" & county_name == \"STATEWIDE WRITEIN\")) %&gt;% \n  filter(!(state == \"MAINE\" & county_name == \"MAINE UOCAVA\")) %&gt;% \n  filter(!(state == \"RHODE ISLAND\" & county_name == \"FEDERAL PRECINCT\"))\n\n#filter for only 2-party vote in presidential elections\ndata &lt;- data %&gt;% \n  filter(office == \"US PRESIDENT\",\n         party == \"DEMOCRAT\" | party == \"REPUBLICAN\") %&gt;% \n  arrange(state, county_name, fips_raw, year) %&gt;% \n  replace_na(list(candidatevotes = 0))\n\nMany of the FIPS codes from the source data dropped leading zeroes, which makes them unuseable for joining with Census data. This code adds the leading zeroes back.\nThese problems were fixed in a later update by MIT, so this code is not strictly necessary anymore\n\n#clean fips data\nstates_with_bad_fips &lt;- str_to_title(c(\"ALABAMA\", \"ALASKA\", \"ARIZONA\", \n                                      \"ARKANSAS\", \"CALIFORNIA\",\n                                      \"COLORADO\", \"CONNECTICUT\"))\ndata %&gt;% \n  filter(state %in% states_with_bad_fips) %&gt;% \n  mutate(county_fips = paste0(\"0\", fips_raw)) %&gt;% \n  distinct(fips_raw, county_fips)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: fips_raw &lt;chr&gt;, county_fips &lt;chr&gt;\n\ndata &lt;- data %&gt;% \n  #add \"0\" to front of states where leading \"0\" was dropped\n  mutate(county_fips = case_when(state %in% states_with_bad_fips ~ paste0(\"0\", fips_raw),\n                          !(state %in% states_with_bad_fips) ~ fips_raw))\n\nI had to make a variety of decisions about how to clean up the data with regards to county geometries. The MIT data does not reflect cases where counties changed names or FIPS codes, or where counties merged. This code manually makes the changes necessary to join the data with Census geometry data. Note that I do not attempt to fix the data for Alaska, which was extremely different than the Census data. I was not confident that I could make accurate adjustments in this case, so I excluded Alaska entirely. These changes are not optimal, but I think it is close enough.\nThese problems were fixed in a later update by MIT, so this code is not strictly necessary anymore\n\n#decisions to make with wonky geometry\n#merge records for Shannnon and Oglala Lakota counties in SD\n#merge Kansas City Missouri and Jackson County Missouri\n#merge Bedford (city) fips 51515 with Bedford county 51019\n\ndata &lt;- data %&gt;% \n  #update Oglala Lakota SD fips\n  #changed in 2015 https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.2010.html\n  mutate(county_fips = case_when(state == \"SOUTH DAKOTA\" & county_name == \"OGLALA LAKOTA\" ~ \"46102\",\n                          TRUE ~ county_fips)) %&gt;% \n  #merge Kansas City Missouri with Jackson County Missouri\n  mutate(county_name = case_when(state == \"MISSOURI\" & county_name == \"KANSAS CITY\" ~ \"JACKSON\",\n                            TRUE ~ county_name),\n         county_fips = case_when(state == \"MISSOURI\" & county_name == \"JACKSON\" ~ \"29095\",\n                          TRUE ~ county_fips)) %&gt;% \n  #merge Bedford (city) fips 51515 with Bedford county 51019\n  mutate(county_fips = case_when(state == \"VIRGINIA\" & county_name == \"BEDFORD\" & county_fips == \"51515\" ~ \"51019\",\n                          TRUE ~ county_fips))\n\nThis compares the counties in the MIT data vs. what is in the Census API. Besides Alaska, this shows that my manual changes accounted for the issues I identified.\n\ncounties &lt;- get_acs(variables = \"B19013_001\",\n                      geography = \"county\",\n                      geometry = FALSE) %&gt;% \n  #mutate(census_geo_year = 2010) %&gt;% \n  select(NAME, GEOID)\n\nGetting data from the 2017-2021 5-year ACS\n\n\n\n#alaska falls out: this is expected\n#Broomfield County CO falls out for year 2000: was part of Boulder County in 2000\n#Oglala Lakota County SD falls out for year 2000: was Shannon County in 2000\n#\ndata %&gt;% \n  select(year, state, county_name, county_fips) %&gt;% \n  filter(state != \"ALASKA\") %&gt;% \n  anti_join(counties, by = c(\"county_fips\" = \"GEOID\")) %&gt;% \n  count(state, county_name)\n\n# A tibble: 1 × 3\n  state        county_name     n\n  &lt;chr&gt;        &lt;chr&gt;       &lt;int&gt;\n1 SOUTH DAKOTA SHANNON         8\n\n\nThe process of merging some counties meant that I had to summarize the election results to the level of my new “adjusted” counties. This code performs that process.\n\n#some counties have 4 records because of merging process\ndata %&gt;%\n  select(state, county_name, county_fips, year) %&gt;% \n  add_count(state, county_name, county_fips, year) %&gt;% \n  distinct(n)\n\n# A tibble: 2 × 1\n      n\n  &lt;int&gt;\n1     2\n2     4\n\n\n\n#summarize candidatevotes to account for merged counties\ndata %&gt;% \n  select(state, county_name, county_fips, year, office, party, candidate, candidatevotes) %&gt;% \n  group_by(state, county_name, county_fips, year, office, party, candidate) %&gt;% \n  summarize(candidatevotes_sum = sum(candidatevotes)) %&gt;% \n  ungroup() %&gt;% \n  add_count(state, county_name, county_fips, year) %&gt;% \n  #confirm that each county only has 2 records\n  distinct(n)\n\n`summarise()` has grouped output by 'state', 'county_name', 'county_fips',\n'year', 'office', 'party'. You can override using the `.groups` argument.\n\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1     2\n\n\n\ndata &lt;- data %&gt;% \n  select(state, county_name, county_fips, year, office, party, candidate, candidatevotes) %&gt;% \n  group_by(state, county_name, county_fips, year, office, party, candidate) %&gt;% \n  summarize(candidatevotes_sum = sum(candidatevotes)) %&gt;% \n  ungroup()\n\n`summarise()` has grouped output by 'state', 'county_name', 'county_fips',\n'year', 'office', 'party'. You can override using the `.groups` argument.\n\n\n\n\nMunge\nThis part performs the more straightfoward tasks of calculating a candidate’s % of the vote and the election-to-election shift in %.\n\npresidential_votes &lt;- data %&gt;% \n  group_by(year, state, county_name, county_fips) %&gt;% \n  mutate(pct_vote = candidatevotes_sum / sum(candidatevotes_sum)) %&gt;% \n  ungroup() %&gt;% \n  select(year, state, county_name, county_fips, party, candidatevotes_sum, pct_vote)\n\n\npresidential_votes_shift &lt;- presidential_votes %&gt;% \n  mutate(party = str_to_lower(party)) %&gt;%\n  pivot_wider(names_from = party, values_from = c(candidatevotes_sum, pct_vote)) %&gt;%\n  mutate(dem_margin_pct = pct_vote_democrat - pct_vote_republican,\n         dem_margin_votes = candidatevotes_sum_democrat - candidatevotes_sum_republican) %&gt;% \n  arrange(state, county_name, county_fips, year) %&gt;% \n  group_by(state, county_name, county_fips) %&gt;% \n  mutate(shift_pct = dem_margin_pct - lag(dem_margin_pct),\n         shift_votes = dem_margin_votes - lag(dem_margin_votes)) %&gt;% \n  filter(row_number() &gt; 1) %&gt;% \n  ungroup()\n\nFinally, this creates new variables that rescale the shift in % and votes to degrees and meters, respectively. I also create variations of shift_pct and shift_votes to use in the graph.\n\npresidential_votes_shift &lt;- presidential_votes_shift %&gt;% \n  mutate(shift_pct_scaled = rescale(shift_pct, to = c(0, 180)), #republican 0, democrat 180\n         shift_votes_scaled = rescale(abs(shift_votes), to = c(10^4, 10^6))) %&gt;% \n  mutate(shift_pct_binary = case_when(sign(shift_pct) == 1 ~ \"Democratic\",\n                                      sign(shift_pct) == -1 ~ \"Republican\"),\n         shift_pct_binary = as.factor(shift_pct_binary)) %&gt;% \n  mutate(shift_votes_binned = abs(shift_votes) &lt;= 3000)\n\n\n#create shift map object\nshift_map &lt;- presidential_votes_shift %&gt;% \n  left_join(county_geo, by = c(\"county_fips\" = \"GEOID\")) %&gt;% \n  st_sf() %&gt;% \n  rename(lng0 = center_lon_x,\n         lat0 = center_lat_y) %&gt;% \n  mutate(lng1 = lng0 + (shift_votes_scaled * cos(NISTdegTOradian(shift_pct_scaled))),\n         lat1 = lat0 + (shift_votes_scaled * sin(NISTdegTOradian(shift_pct_scaled))))\n\n\nshift_map_filtered &lt;- shift_map %&gt;% \n  filter(state != \"ALASKA\") %&gt;%\n  filter(year == 2016) %&gt;% \n  mutate(shift_pct_binary = case_when(sign(shift_pct) == 1 ~ \"Democratic\",\n                                      sign(shift_pct) == -1 ~ \"Republican\"),\n         shift_pct_binary = as.factor(shift_pct_binary))\n\nggplot() +\n  geom_sf(data = filter(state_geo, !str_detect(NAME, \"ALASKA\")),\n          linewidth = .2,\n          fill = NA) +\n  geom_point(data = filter(shift_map_filtered, abs(shift_votes) &lt;= 1500),\n             aes(x = lng0, y = lat0,\n                 color = shift_pct_binary),\n             size = .75,\n             alpha = .3) +\n  geom_segment(data = filter(shift_map_filtered, abs(shift_votes) &gt; 1500),\n               aes(x = lng0, xend = lng1,\n                   y = lat0, yend = lat1,\n                   color = shift_pct_binary,\n                   linewidth = shift_votes,\n                   alpha = shift_votes_binned),\n               linejoin = \"mitre\",\n               arrow = arrow(length = unit(0.08, \"inches\"))) +\n  scale_color_manual(values = c(\"#1375B7\", \"#C93135\"), guide = guide_legend(title.position = \"top\")) +\n  scale_linewidth_continuous(range = c(.001, 2), guide = \"none\") +\n  scale_alpha_manual(values = c(1, .3), guide = \"none\") +\n  labs(color = \"Shift in election margin\") +\n  facet_wrap(~year) +\n  theme_void(base_size = 25) +\n  theme(legend.direction = \"horizontal\",\n        legend.position = \"bottom\")\n\n\npolitical_winds_anim &lt;- shift_map %&gt;% \n  filter(state != \"Alaska\") %&gt;% \n  mutate(id = str_c(state, county_name, county_fips)) %&gt;% \n  mutate(year = as.integer(year)) %&gt;% \n  mutate(shift_votes_binned = abs(shift_votes) &lt;= 3000) %&gt;% \n  ggplot() +\n  geom_sf(data = filter(state_geo, NAME != \"Alaska\"),\n          linewidth = .2,\n          fill = NA) +\n  geom_segment(aes(x = lng0, xend = lng1,\n                   y = lat0, yend = lat1,\n                   color = shift_pct_binary,\n                   linewidth = shift_votes,\n                   alpha = shift_votes_binned,\n                   group = id),\n               linejoin = \"mitre\",\n               arrow = arrow(length = unit(0.09, \"inches\"))) +\n  scale_color_manual(values = c(\"#1375B7\", \"#C93135\"), guide = guide_legend(title.position = \"top\")) +\n  scale_size_continuous(range = c(.001, 1.3), guide = \"none\") +\n  scale_alpha_manual(values = c(1, .3), guide = \"none\") +\n  theme_void(base_size = 25) +\n  theme(legend.direction = \"horizontal\",\n        legend.position = \"bottom\") +\n  transition_states(year) +\n  labs(title = \"Shift in Presidential election Democratic margin\",\n       subtitle = \"Year: {closest_state}\",\n       color = \"Shift in Democratic margin\")\n\npolitical_winds_anim"
  },
  {
    "objectID": "posts/bivariate_transit_map/index.html",
    "href": "posts/bivariate_transit_map/index.html",
    "title": "Driving Alone vs. Public Transportation in Pittsburgh",
    "section": "",
    "text": "Intro\nThe clash between public transportation and single passenger vehicles is a heated topic of discussion nationally and in the Pittsburgh area. Public transit ridership has been heavily reduced by COVID-19 in many countries. These two commuting modes compete for the same riders, and investment dollars, and space. Car drivers are frustrated when a bus stops during rush hour to pick up passengers, while bus passengers are frustrated sitting in traffic caused by single passenger vehicles because transit doesn’t have right-of-way.\nFrom my point of view, Pittsburgh’s geography lends itself to a focus on public transit, at the expense of the single passenger vehicle. Most of the jobs in the county are in a single census tract Downtown, which is reflected in the spoke (and no wheel) design of the transit system. Downtown is surrounded by rivers and mountains, which drastically narrows the geography suited to infrastructure. You pretty much have to use a tunnel or bridge to commute Downtown, unless you are coming from directly east. It would make sense to give public transit priority access to those tunnels and bridges, since their throughput is many times higher than roads designated for single passenger vehicles.\n\n\n\n\n\nThe historical priority towards single passenger vehicles is reflected in the Census statistics about commuting modes in the area. Most people in the area commute to work by themselves in cars. In the Wexford-area census tract, 78% (5,141) of commuters drive to work alone (and sit in traffic on the parkway together). Public transit use is limited to areas where the government invested in transit, but even there transit is not typically the majority mode.\nIn this post I will use {tidycensus} to pull data about how many people commute by driving alone or taking public transit Allegheny County. I chose these two modes because they are the two most popular modes in the county, and are the most different in terms of style. I then graph the data with {ggplot2} and {biscale}. I hack the {biscale} legend a bit to get it to show the % of commuters, which may be of interest to other R users.\n\n\nCode and graphs\nLoad libraries and set up the environment:\n\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(sf)\nlibrary(tigris)\nlibrary(janitor)\nlibrary(biscale)\nlibrary(patchwork)\nlibrary(hrbrthemes)\nlibrary(kableExtra)\n\noptions(scipen = 999, digits = 4)\n\ntheme_set(theme_ipsum(base_size = 25))\n\nThese are the variables about commuter mode that the Census has for the 2019 American Community Survey (ACS):\n\nacs1_vars &lt;- load_variables(2019, 'acs1') %&gt;% \n  mutate(across(c(label, concept), str_to_lower))\n\nacs1_vars %&gt;%\n  filter(str_detect(name, \"^B08301_\")) %&gt;% \n  kbl() %&gt;% \n  scroll_box(height = \"400px\") %&gt;% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n                position = \"left\")\n\n\n\n\n\n\nname\nlabel\nconcept\n\n\n\n\nB08301_001\nestimate!!total:\nmeans of transportation to work\n\n\nB08301_002\nestimate!!total:!!car, truck, or van:\nmeans of transportation to work\n\n\nB08301_003\nestimate!!total:!!car, truck, or van:!!drove alone\nmeans of transportation to work\n\n\nB08301_004\nestimate!!total:!!car, truck, or van:!!carpooled:\nmeans of transportation to work\n\n\nB08301_005\nestimate!!total:!!car, truck, or van:!!carpooled:!!in 2-person carpool\nmeans of transportation to work\n\n\nB08301_006\nestimate!!total:!!car, truck, or van:!!carpooled:!!in 3-person carpool\nmeans of transportation to work\n\n\nB08301_007\nestimate!!total:!!car, truck, or van:!!carpooled:!!in 4-person carpool\nmeans of transportation to work\n\n\nB08301_008\nestimate!!total:!!car, truck, or van:!!carpooled:!!in 5- or 6-person carpool\nmeans of transportation to work\n\n\nB08301_009\nestimate!!total:!!car, truck, or van:!!carpooled:!!in 7-or-more-person carpool\nmeans of transportation to work\n\n\nB08301_010\nestimate!!total:!!public transportation (excluding taxicab):\nmeans of transportation to work\n\n\nB08301_011\nestimate!!total:!!public transportation (excluding taxicab):!!bus\nmeans of transportation to work\n\n\nB08301_012\nestimate!!total:!!public transportation (excluding taxicab):!!subway or elevated rail\nmeans of transportation to work\n\n\nB08301_013\nestimate!!total:!!public transportation (excluding taxicab):!!long-distance train or commuter rail\nmeans of transportation to work\n\n\nB08301_014\nestimate!!total:!!public transportation (excluding taxicab):!!light rail, streetcar or trolley (carro público in puerto rico)\nmeans of transportation to work\n\n\nB08301_015\nestimate!!total:!!public transportation (excluding taxicab):!!ferryboat\nmeans of transportation to work\n\n\nB08301_016\nestimate!!total:!!taxicab\nmeans of transportation to work\n\n\nB08301_017\nestimate!!total:!!motorcycle\nmeans of transportation to work\n\n\nB08301_018\nestimate!!total:!!bicycle\nmeans of transportation to work\n\n\nB08301_019\nestimate!!total:!!walked\nmeans of transportation to work\n\n\nB08301_020\nestimate!!total:!!other means\nmeans of transportation to work\n\n\nB08301_021\nestimate!!total:!!worked from home\nmeans of transportation to work\n\n\n\n\n\n\n\nDriving alone in a single-passenger vehicle is by far the dominant commuting mode in the county.\n\nall_transit_vars &lt;- c(\"B08301_003\", \n                      \"B08301_004\", \n                      \"B08301_010\", \n                      \"B08301_016\", \n                      \"B08301_017\", \n                      \"B08301_018\", \n                      \"B08301_019\", \n                      \"B08301_020\",\n                      \"B08301_021\")\n\nall_transit_modes &lt;- get_acs(geography = \"county\", \n                             variables = acs1_vars %&gt;%\n                               filter(name %in% all_transit_vars) %&gt;% \n                               pull(name, label),\n                             summary_var = \"B08301_001\",\n                             year = 2019, state = \"PA\", county = \"Allegheny\",\n                             geometry = F)\n\nall_transit_modes %&gt;% \n  mutate(variable = str_remove(variable, \"^estimate!!total:\"),\n         variable = str_remove(variable, \"\\\\(excluding taxicab\\\\)\"),\n         variable = str_remove_all(variable, \"\\\\!\"),\n         variable = str_remove(variable, \":$\"),\n         variable = str_replace(variable, \":\", \" : \"),\n         variable = str_trim(variable),\n         variable = str_to_title(variable)) %&gt;% \n  group_by(variable) %&gt;% \n  summarize(estimate = sum(estimate),) %&gt;% \n  mutate(variable = fct_reorder(variable, estimate),\n         pct = estimate / sum(estimate)) %&gt;% \n  ggplot(aes(estimate, variable)) +\n  geom_col() +\n  geom_text(aes(x = estimate + 26000, label = scales::percent(pct, 1)),\n            size = 4) +\n  labs(title = \"Allegheny County Commuter Modes\",\n       subtitle = \"2019 American Community Survey\",\n       x = \"Commuters\",\n       y = NULL) +\n  scale_x_comma(limits = c(0, 500000),\n                labels = c(\"0\", \"1k\", \"2k\", \"3k\", \"4k\", \"5k\")) +\n  theme_ipsum(axis_text_size = 15)\n\n\n\n\nI will use these two variables to directly compare the use of single-passenger vehicles and public transit in the county.\n\nvars &lt;- c(\"Drove alone\" = \"B08301_003\",\n          \"Public transportation\" = \"B08301_010\")\n\nacs1_vars %&gt;%\n  filter(name %in% vars) %&gt;% \n  pull(label)\n\n[1] \"estimate!!total:!!car, truck, or van:!!drove alone\"          \n[2] \"estimate!!total:!!public transportation (excluding taxicab):\"\n\n\nThis downloads the commuter mode data and subtracts the rivers from the census tract polygons so it looks nice on a map:\n\ntract_transit %&gt;% \n  glimpse()\n\nRows: 804\nColumns: 5\n$ GEOID       &lt;chr&gt; \"42003408002\", \"42003408002\", \"42003210700\", \"42003210700\"…\n$ variable    &lt;chr&gt; \"Drove alone\", \"Public transportation\", \"Drove alone\", \"Pu…\n$ estimate    &lt;dbl&gt; 2815, 8, 589, 189, 566, 146, 1224, 260, 466, 100, 1063, 21…\n$ summary_est &lt;dbl&gt; 3165, 3165, 1231, 1231, 1110, 1110, 1992, 1992, 702, 702, …\n$ geometry    &lt;POLYGON [°]&gt; POLYGON ((-79.99 40.61, -79..., POLYGON ((-79.99 4…\n\n\nAs discussed earlier, public transit is not the majority commuting mode in most areas:\n\ntract_transit %&gt;% \n  st_drop_geometry() %&gt;% \n  group_by(GEOID) %&gt;%\n  mutate(pct_tract_commuters = estimate / sum(estimate),\n         combined_commuters = sum(estimate)) %&gt;%\n  ungroup() %&gt;%\n  mutate(GEOID = fct_reorder(GEOID, summary_est)) %&gt;%\n  arrange(desc(GEOID), desc(summary_est)) %&gt;% \n  mutate(is_downtown_label = case_when(GEOID == \"42003020100\" & variable == \"Drove alone\" ~ \"Downtown*\",\n                                       TRUE ~ NA_character_)) %&gt;% \n  slice(1:60) %&gt;% \n  ggplot(aes(estimate, GEOID, fill = variable)) +\n  geom_col(color = \"black\") +\n  geom_text(aes(x = estimate + 3000, label = is_downtown_label)) +\n  labs(title = \"Top 30 census tracts\",\n       subtitle = \"Total commuter population from all modes\",\n       x = \"Commuters\",\n       y = \"Census tracts\",\n       fill = \"Commute mode\") +\n  scale_x_comma() +\n  theme_ipsum(base_size = 15) +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major = element_blank())\n\n\n\n\n*Most commuters that live in Downtown walk to work.\nThis shows that in absolute numbers, driving alone swamps public transit across the county.\n\nscatter_graph &lt;- tract_transit %&gt;% \n  st_drop_geometry() %&gt;% \n  select(GEOID, variable, estimate) %&gt;% \n  pivot_wider(names_from = variable, values_from = estimate) %&gt;% \n  clean_names() %&gt;% \n  ggplot(aes(drove_alone, public_transportation)) +\n  geom_point(alpha = .7, size = 1) +\n  labs(title = \"Commuter modes in Allegheny County\",\n       x = \"Driving Alone\",\n       y = \"Using Public Transportation\") +\n  scale_x_comma() +\n  scale_y_comma() +\n  tune::coord_obs_pred() +\n  theme_ipsum(base_size = 15)\n\nscatter_graph\n\n\n\n\nI made the X and Y axes symmetric to emphasize the difference in scale between the two variables.\nThis uses the bi_class function to divide the data into discrete bins based on how many people drive alone vs. use public transit. This turns two continuous variables into one categorical variable. I had to play around with the style argument to find an option that worked for the unbalanced data.\n\ntransit_bivariate_geo &lt;- tract_transit %&gt;% \n  st_drop_geometry() %&gt;% \n  drop_na(estimate) %&gt;% \n  select(GEOID, variable, estimate) %&gt;% \n  pivot_wider(names_from = variable, values_from = estimate) %&gt;% \n  clean_names() %&gt;% \n  replace_na(list(drove_alone = 0, public_transportation = 0)) %&gt;% \n  bi_class(x = drove_alone, \n           y = public_transportation, \n           style = \"fisher\", \n           dim = 3) %&gt;% \n  left_join(tracts, \n            by = c(\"geoid\" = \"GEOID\")) %&gt;% \n  st_sf()\n\nglimpse(transit_bivariate_geo)\n\nRows: 402\nColumns: 9\n$ geoid                 &lt;chr&gt; \"42003408002\", \"42003210700\", \"42003220600\", \"42…\n$ drove_alone           &lt;dbl&gt; 2815, 589, 566, 1224, 466, 1063, 887, 826, 551, …\n$ public_transportation &lt;dbl&gt; 8, 189, 146, 260, 100, 215, 262, 342, 670, 61, 3…\n$ bi_class              &lt;chr&gt; \"3-1\", \"1-2\", \"1-1\", \"2-2\", \"1-1\", \"2-2\", \"1-2\",…\n$ NAME                  &lt;chr&gt; \"Census Tract 4080.02, Allegheny County, Pennsyl…\n$ variable              &lt;chr&gt; \"B08301_001\", \"B08301_001\", \"B08301_001\", \"B0830…\n$ estimate              &lt;dbl&gt; 3165, 1231, 1110, 1992, 702, 1487, 1317, 1712, 1…\n$ moe                   &lt;dbl&gt; 231, 199, 116, 189, 80, 233, 163, 185, 257, 104,…\n$ geometry              &lt;POLYGON [°]&gt; POLYGON ((-79.99 40.61, -79..., POLYGON …\n\n\n\ntable(transit_bivariate_geo$bi_class) %&gt;% \n  enframe(name = \"bi_class\", value = \"count_tracts\") %&gt;% \n  kbl()\n\n\n\n\nbi_class\ncount_tracts\n\n\n\n\n1-1\n124\n\n\n1-2\n72\n\n\n1-3\n9\n\n\n2-1\n84\n\n\n2-2\n66\n\n\n2-3\n9\n\n\n3-1\n34\n\n\n3-2\n4\n\n\n\n\n\n\n\nThis graph overlays the discrete biscale bins on the previous data to show how the function discretized the data.\n\ntransit_bivariate_geo %&gt;% \n  ggplot(aes(drove_alone, public_transportation, color = bi_class)) +\n  geom_point(alpha = .75, size = 1) +\n  scale_x_comma() +\n  labs(x = \"Drove Alone\",\n       y = \"Used Public Transit\") +\n  guides(color = FALSE) +\n  theme_ipsum(base_size = 15)\n\n\n\n\nNote that the X and Y axes are independent in this graph.\nThis creates the biscale legend I will put next to the map.\n\nbi_var_legend &lt;- bi_legend(pal = \"DkBlue\",\n                           dim = 3,\n                           xlab = \" More drove alone\",\n                           ylab = \"More used public transit\",\n                           size = 26) +\n  theme(plot.background = element_rect(fill = alpha(\"white\", 0)),\n        panel.background = element_rect(fill = alpha(\"white\", 0)))\n\nbi_var_legend\n\n\n\n\nI would like to show the % of commuters that each bin represents, so I extract the color palette from the ggplot2 object and make my own legend with geom_tile.\n\nbuilt_legend &lt;- ggplot_build(bi_var_legend)\n\nlegend_palette &lt;- built_legend$data[[1]] %&gt;%\n  mutate(bi_class = str_c(x, y, sep = \"-\")) %&gt;% \n  select(fill, bi_class)\n\nlegend_palette %&gt;% \n  kbl()\n\n\n\n\nfill\nbi_class\n\n\n\n\n#e8e8e8\n1-1\n\n\n#ace4e4\n2-1\n\n\n#5ac8c8\n3-1\n\n\n#dfb0d6\n1-2\n\n\n#a5add3\n2-2\n\n\n#5698b9\n3-2\n\n\n#be64ac\n1-3\n\n\n#8c62aa\n2-3\n\n\n#3b4994\n3-3\n\n\n\n\n\n\n\n\ntransit_bivariate &lt;- transit_bivariate_geo %&gt;% \n  st_drop_geometry() %&gt;% \n  select(geoid, bi_class, drove_alone, public_transportation) %&gt;% \n  separate(bi_class, \n           into = c(\"drove_alone_bi\", \"public_transportation_bi\"), \n           sep = \"-\",\n           remove = FALSE) %&gt;% \n  complete(drove_alone_bi, public_transportation_bi, fill = list(drove_alone = 0, public_transportation = 0)) %&gt;% \n  mutate(bi_class = str_c(drove_alone_bi, public_transportation_bi, sep = \"-\"),\n         total = drove_alone + public_transportation,\n         pct_commuters = total / sum(total)) %&gt;%\n  group_by(bi_class, drove_alone_bi, public_transportation_bi) %&gt;% \n  summarize(count_tract = n(),\n            pct_commuters = sum(pct_commuters)) %&gt;% \n  ungroup()\n\nglimpse(transit_bivariate)\n\nRows: 9\nColumns: 5\n$ bi_class                 &lt;chr&gt; \"1-1\", \"1-2\", \"1-3\", \"2-1\", \"2-2\", \"2-3\", \"3-…\n$ drove_alone_bi           &lt;chr&gt; \"1\", \"1\", \"1\", \"2\", \"2\", \"2\", \"3\", \"3\", \"3\"\n$ public_transportation_bi &lt;chr&gt; \"1\", \"2\", \"3\", \"1\", \"2\", \"3\", \"1\", \"2\", \"3\"\n$ count_tract              &lt;int&gt; 124, 72, 9, 84, 66, 9, 34, 4, 1\n$ pct_commuters            &lt;dbl&gt; 0.13661, 0.11754, 0.02073, 0.25273, 0.22252, …\n\n\n\nlegend_palette &lt;- transit_bivariate %&gt;% \n  distinct(bi_class) %&gt;% \n  left_join(legend_palette, by = \"bi_class\")\n\nlegend_palette %&gt;% \n  kbl()\n\n\n\n\nbi_class\nfill\n\n\n\n\n1-1\n#e8e8e8\n\n\n1-2\n#dfb0d6\n\n\n1-3\n#be64ac\n\n\n2-1\n#ace4e4\n\n\n2-2\n#a5add3\n\n\n2-3\n#8c62aa\n\n\n3-1\n#5ac8c8\n\n\n3-2\n#5698b9\n\n\n3-3\n#3b4994\n\n\n\n\n\n\n\nNote that scale_fill_manual uses the palette I extracted from the ggplot2 object.\n\nbi_var_legend_new &lt;- transit_bivariate %&gt;% \n  mutate(pct_commuters = scales::percent(pct_commuters, accuracy = 1)) %&gt;% \n  ggplot(aes(x = drove_alone_bi, y = public_transportation_bi, fill = bi_class)) +\n  geom_tile() +\n  geom_label(fill = \"white\", alpha = .75, size = 12, label = \"    \") +\n  geom_text(aes(label = pct_commuters), alpha = 1, size = 7) +\n  coord_fixed(ratio = 1) +\n  labs(x = substitute(paste(\"More drove alone\", \"\" %-&gt;% \"\")),\n       y = substitute(paste(\"More used public transit\", \"\" %-&gt;% \"\"))) +\n  guides(fill = FALSE) +\n  scale_fill_manual(values = pull(legend_palette, fill)) +\n  theme_ipsum(plot_title_size = 30,\n              axis_title_size = 30) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank())\n\nbi_var_legend_new +\n  labs(title = 'Percent of \"drive alone\" + \"public transit\" commuters')\n\n\n\n\nThis creates the map of commuter mode by census tract, filled by the discretized biscale bin.\n\ntransit_bi_var_plot &lt;- transit_bivariate_geo %&gt;% \n  ggplot(aes(fill = bi_class)) +\n  geom_sf(show.legend = FALSE, lwd = 0) +\n  geom_sf(data = rivers, fill = \"black\", color = \"black\") +\n  bi_scale_fill(pal = \"DkBlue\", dim = 3) +\n  bi_theme() +\n  theme_ipsum(base_size = 15) +\n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank())\n\ntransit_bi_var_plot\n\n\n\n\nNow that I have my legend and map, I use patchwork to stitch them together.\n\ndesign = c(area(t = 2, l = 4, b = 20, r = 20),\n           area(t = 1, l = 1, b = 6, r = 6))\n\nplot(design)\n\n\n\n\n\ncombined_bi_var_plot &lt;- transit_bi_var_plot + bi_var_legend_new +\n  plot_layout(design = design) +\n  plot_annotation(title = \"Allegheny County Commuter Patterns\",\n                  subtitle = \"Legend: % of commuters that drove alone or use public transit\",\n                  caption = \"2019 American Community Survey\",\n                  theme = theme(panel.background = element_rect(fill = \"black\"),\n                                plot.title = element_text(size = 30),\n                                plot.subtitle = element_text(size = 25),\n                                plot.caption = element_text(size = 25)))\n\n\n\n\n\n\n\nLinks:\n\nhttps://www.pghcitypaper.com/pittsburgh/low-income-pittsburghers-are-becoming-increasingly-reliant-on-public-transit-bikes-walking-and-alternative-transportation/Content?oid=19059768\nhttps://www.pghcitypaper.com/pittsburgh/new-commutes-analyzing-the-changing-ways-pittsburghers-get-to-work/Content?oid=6405396\nhttps://www.pghcitypaper.com/pittsburgh/pittsburgh-is-the-7th-least-car-dependent-metro-in-america-study-says/Content?oid=16755873\nhttps://www.nytimes.com/2020/07/09/opinion/sunday/ban-cars-manhattan-cities.html\nhttps://www.nytimes.com/2021/03/25/climate/buses-trains-ridership-climate-change.html\nhttps://nacto.org/publication/transit-street-design-guide/introduction/why/designing-move-people/\nhttps://rweekly.org/"
  },
  {
    "objectID": "posts/house_price_estimator/index.html",
    "href": "posts/house_price_estimator/index.html",
    "title": "House Price Estimator Dashboard",
    "section": "",
    "text": "Click here to view the full dashboard"
  },
  {
    "objectID": "posts/house_price_estimator/index.html#training-set-metrics-75-of-total-observations",
    "href": "posts/house_price_estimator/index.html#training-set-metrics-75-of-total-observations",
    "title": "House Price Estimator Dashboard",
    "section": "Training set metrics (75% of total observations)",
    "text": "Training set metrics (75% of total observations)\nI used 10-fold cross-validation to assess model performance against the training set:\n\ntrain_metrics %&gt;% \n  select(model_name, id, .metric, .estimate) %&gt;% \n  pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% \n  ggplot(aes(rmse, rsq, color = model_name)) +\n  geom_point() +\n  scale_x_continuous(label = dollar) +\n  labs(x = \"Root Mean Squared Error\",\n       y = \"R^2\")"
  },
  {
    "objectID": "posts/house_price_estimator/index.html#test-set-metrics-25-of-total-observations",
    "href": "posts/house_price_estimator/index.html#test-set-metrics-25-of-total-observations",
    "title": "House Price Estimator Dashboard",
    "section": "Test set metrics (25% of total observations)",
    "text": "Test set metrics (25% of total observations)\n\ntest_metrics %&gt;% \n  select(.metric, .estimate)\n\n# A tibble: 3 × 2\n  .metric   .estimate\n  &lt;chr&gt;         &lt;dbl&gt;\n1 rmse     251406.   \n2 rsq           0.607\n3 mape    3724488.   \n\n\n\nmodel_results %&gt;% \n  ggplot(aes(.resid)) +\n  geom_density() +\n  geom_vline(xintercept = 0, lty = 2) +\n  scale_x_continuous(label = label_dollar())\n\n\n\n\n\nmodel_results %&gt;% \n  ggplot(aes(sale_price_adj, .pred_dollar)) +\n  geom_density_2d_filled(contour_var = \"count\") +\n  scale_x_log10(label = label_dollar()) +\n  scale_y_log10(label = label_dollar()) +\n  guides(fill = guide_coloursteps()) +\n  labs(x = \"Inflation-adjusted sale price log10 scale\",\n       y = \"Prediction\",\n       fill = \"Sales\")\n\n\n\n\nThe model becomes less effective as the actual sale price increases.\n\nmodel_results %&gt;% \n  ggplot(aes(sale_price_adj, .resid)) +\n  geom_point(alpha = .01) +\n  scale_x_log10(label = dollar) +\n  scale_y_continuous(label = dollar) +\n  labs(x = \"Inflation-adjusted sale price log10 scale\",\n       y = \"Residual\")\n\n\n\n\n\ngeo_ids &lt;- st_read(\"post_data/unified_geo_ids/unified_geo_ids.shp\",\n                   quiet = T)\n\ngeo_id_median_resid &lt;- model_results %&gt;% \n  group_by(geo_id) %&gt;% \n  summarize(median_resid = median(.resid))\n\npal &lt;- colorNumeric(\n  palette = \"viridis\",\n  domain = geo_id_median_resid$median_resid)\n\ngeo_ids %&gt;% \n  left_join(geo_id_median_resid) %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap.Mapnik,\n                   options = providerTileOptions(noWrap = TRUE,\n                                                 minZoom = 9\n                                                 #maxZoom = 8\n                   )) %&gt;%\n  addPolygons(popup = ~ str_c(geo_id, \" \", \"median residual: \", round(median_resid, 2), sep = \"\"),\n              fillColor = ~pal(median_resid),\n              fillOpacity = .7,\n              color = \"black\",\n              weight = 3) %&gt;% \n  addLegend(\"bottomright\", pal = pal, values = ~median_resid,\n            title = \"Median of residual\",\n            opacity = 1)\n\nJoining with `by = join_by(geo_id)`\n\n\n\n\n\n\n\nmodel_results %&gt;% \n  add_count(geo_id) %&gt;% \n  mutate(geo_id = fct_reorder(geo_id, .resid, .fun = median)) %&gt;% \n  ggplot(aes(.resid, geo_id, fill = n)) +\n  geom_boxplot(color = \"grey\",\n               outlier.alpha = 0) +\n  geom_vline(xintercept = 0, lty = 2, color = \"red\") +\n  scale_fill_viridis_c() +\n  coord_cartesian(xlim = c(-10^5, 10^5)) +\n  labs(fill = \"Sales\")\n\n\n\n\n\nmodel_results %&gt;% \n  add_count(style_desc) %&gt;% \n  mutate(style_desc = fct_reorder(style_desc, .resid, .fun = median)) %&gt;% \n  ggplot(aes(.resid, style_desc, fill = n)) +\n  geom_boxplot(color = \"grey\",\n               outlier.alpha = 0) +\n  geom_vline(xintercept = 0, lty = 2, color = \"red\") +\n  coord_cartesian(xlim = c(-10.5^5, 10.5^5)) +\n  scale_x_continuous(labels = label_dollar()) +\n  scale_fill_viridis_c() +\n  labs(fill = \"Sales\",\n       x = \"Residual\",\n       y = \"House style\")\n\n\n\n\n\nmodel_results %&gt;% \n  add_count(grade_desc) %&gt;% \n  mutate(grade_desc = fct_reorder(grade_desc, .resid, .fun = median)) %&gt;% \n  ggplot(aes(.resid, grade_desc, fill = n)) +\n  geom_boxplot(color = \"grey\",\n               outlier.alpha = 0) +\n  scale_fill_viridis_c() +\n  scale_x_continuous(labels = label_dollar()) +\n  coord_cartesian(xlim = c(-10^5, 10.5^6)) +\n  labs(x = \"Residual\",\n       y = \"Grade\",\n       fill = \"Sales\")\n\n\n\n\n\nmodel_results %&gt;% \n  add_count(condition_desc) %&gt;% \n  mutate(condition_desc = fct_explicit_na(condition_desc),\n         condition_desc = fct_reorder(condition_desc, .resid, .fun = median)) %&gt;% \n  ggplot(aes(.resid, condition_desc, fill = n)) +\n  geom_boxplot(color = \"grey\",\n               outlier.alpha = 0) +\n  geom_vline(xintercept = 0, lty = 2, color = \"red\") +\n  scale_fill_viridis_c() +\n  scale_x_continuous(labels = label_dollar()) +\n  coord_cartesian(xlim = c(-10^5, 10.5^5)) +\n  labs(x = \"Residual\",\n       y = \"Condition\",\n       fill = \"Sales\")\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `condition_desc = fct_explicit_na(condition_desc)`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\n\n\n\n\nmodel_results %&gt;% \n  ggplot(aes(finished_living_area, .resid)) +\n  geom_point(alpha = .1) +\n  scale_x_log10() +\n  scale_y_continuous(label = dollar) +\n  labs(x = \"Finished Living Area sq. ft. log10 scale\",\n       y = \"Residual\")\n\n\n\n\n\nmodel_results %&gt;% \n  ggplot(aes(lot_area, .resid)) +\n  geom_point(alpha = .1) +\n  scale_x_log10(labels = label_comma()) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(x = \"Lot Area sq. ft. log10 scale\",\n       y = \"Residual\")\n\nWarning: Transformation introduced infinite values in continuous x-axis\n\n\n\n\n\n\nmodel_results %&gt;% \n  group_by(house_age_at_sale) %&gt;% \n  rmse(truth = sale_price_adj, estimate = .pred_dollar) %&gt;% \n  ggplot(aes(house_age_at_sale, .estimate)) +\n  geom_point(alpha = .5) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(x = \"House age at sale\",\n       y = \"RMSE\")\n\n\n\n\nThe model is best at predicting the sale price of houses built in the 1940s to 1980s. This is when most of the houses in the county were built.\n\nmodel_results %&gt;% \n  group_by(year_built) %&gt;% \n  rmse(truth = sale_price_adj, estimate = .pred_dollar) %&gt;% \n  ggplot(aes(year_built, .estimate)) +\n  geom_point(alpha = .5) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(x = \"Year Built\",\n       y = \"RMSE\")\n\n\n\n\n\nmodel_results %&gt;% \n  add_count(bedrooms) %&gt;% \n  ggplot(aes(.resid, bedrooms, group = bedrooms, fill = n)) +\n  geom_boxplot(color = \"grey\",\n               outlier.alpha = 0) +\n  geom_vline(xintercept = 0, lty = 2, color = \"red\") +\n  scale_y_continuous(breaks = c(0:15)) +\n  scale_fill_viridis_c() +\n  scale_x_continuous(labels = label_dollar()) +\n  coord_cartesian(xlim = c(-10^5, 10^5)) +\n  labs(x = \"Residual\",\n       y = \"Bedrooms\",\n       fill = \"Sales\")\n\nWarning: Removed 2 rows containing missing values (`stat_boxplot()`).\n\n\n\n\n\n\nmodel_results %&gt;% \n  add_count(full_baths) %&gt;% \n  ggplot(aes(.resid, full_baths, group = full_baths, fill = n)) +\n  geom_boxplot(color = \"grey\",\n               outlier.alpha = 0) +\n  geom_vline(xintercept = 0, lty = 2, color = \"red\") +\n  scale_y_continuous(breaks = c(0:12)) +\n  scale_fill_viridis_c() +\n  scale_x_continuous(label = dollar) +\n  coord_cartesian(xlim = c(-10^5, 750000)) +\n  labs(x = \"Residual\",\n       y = \"Full bathrooms\",\n       fill = \"Sales\")\n\nWarning: Removed 14 rows containing missing values (`stat_boxplot()`).\n\n\n\n\n\n\nmodel_results %&gt;% \n  add_count(half_baths) %&gt;% \n  ggplot(aes(.resid, half_baths, group = half_baths, fill = n)) +\n  geom_boxplot(color = \"grey\",\n               outlier.alpha = 0) +\n  geom_vline(xintercept = 0, lty = 2, color = \"red\") +\n  scale_y_continuous(breaks = c(0:8)) +\n  scale_x_continuous(labels = label_dollar()) +\n  scale_fill_viridis_c() +\n  coord_cartesian(xlim = c(-10^5, 10^5)) +\n  labs(x = \"Residual\",\n       y = \"Half bathrooms\",\n       fill = \"Sales\")\n\nWarning: Removed 785 rows containing missing values (`stat_boxplot()`).\n\n\n\n\n\n\nmodel_results %&gt;% \n  group_by(sale_year) %&gt;% \n  rmse(truth = sale_price_adj, estimate = .pred_dollar) %&gt;% \n  ggplot(aes(sale_year, .estimate)) +\n  geom_line() +\n  scale_y_continuous(label = dollar) +\n  labs(x = \"Sale year\",\n       y = \"RMSE\")"
  },
  {
    "objectID": "posts/healthy_ride_access_pittsburgh/index.html",
    "href": "posts/healthy_ride_access_pittsburgh/index.html",
    "title": "Bike rental access in Pittsburgh",
    "section": "",
    "text": "This is an interactive Leaflet map of Healthy Ride access in Pittsburgh. It counts how many Healthy Ride stations are within a 10 minute bike ride of a given location. This gives an estimation of how accessible the Healthy Ride service is in a given neighborhood (lighter green = more accessible). As you zoom in, individual bike stations will appear. Click the “full screen” button on the left to maximize your view.\nThere are some obvious cases (like the Wabash Tunnel) where the API doesn’t know that a bicyclist shouldn’t go in there, but overall it is accurate.\nThis map was built with the Mapbox API and was inspired by the Penn MUSA Masterclass 2020 talk that Kyle Walker gave."
  },
  {
    "objectID": "posts/healthy_ride_access_pittsburgh/index.html#build-one-isochrone",
    "href": "posts/healthy_ride_access_pittsburgh/index.html#build-one-isochrone",
    "title": "Bike rental access in Pittsburgh",
    "section": "Build one isochrone",
    "text": "Build one isochrone\nThis takes the first station in the dataframe and uses the Mapbox API to make a test isochrone that shows how far a bicyclist can go in a given period of time (5, 10, 15 minutes).\n\ntest_isochrone_data &lt;- stations %&gt;% \n  slice(1) %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  mb_isochrone(profile = \"cycling\", time = c(5, 10, 15))\n\ntest_isochrone_map &lt;- mapbox_map %&gt;% \n  mapdeck() %&gt;% \n  add_polygon(data = test_isochrone_data,\n              fill_colour = \"time\",\n              fill_opacity = 0.5,\n              legend = TRUE) %&gt;% \n  add_scatterplot(data = stations %&gt;% \n                          slice(1) %&gt;% \n                          st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326),\n                  radius = 100,\n                  fill_colour = \"#ffffff\") %&gt;% \n  mapdeck_view(location = c(pgh_coords[1], pgh_coords[2]), zoom = 11)\n\ntest_isochrone_map\n\n\n\n\n\nThe same graph can be made in ggplot2:\n\ntest_isochrone_data %&gt;% \n  ggplot() +\n  geom_sf(aes(fill = time)) +\n  scale_fill_viridis_c() +\n  theme_void()\n\n\n\n\nThis calculates the isochrones for all the stations and transforms them into a projected coordinate system:\n\nstation_isochrone &lt;- stations %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  mb_isochrone(profile = \"cycling\", time = c(10)) %&gt;%\n  st_transform(3857)\n\nThis shows the overlap between all the isochrones. Interesting to look at, but not very informative.\n\nstation_isochrone %&gt;% \n  ggplot() +\n  geom_sf(fill = \"black\", lwd = 0, alpha = .05) +\n  theme_void()"
  },
  {
    "objectID": "posts/healthy_ride_access_pittsburgh/index.html#build-raster",
    "href": "posts/healthy_ride_access_pittsburgh/index.html#build-raster",
    "title": "Bike rental access in Pittsburgh",
    "section": "Build Raster",
    "text": "Build Raster\nThis builds a raster object that calculates how many isochrones overlap on a given area:\n\n#raster\npolygons_proj &lt;- station_isochrone %&gt;%\n  mutate(test_id = 1) %&gt;% \n  filter(time == 10) %&gt;% \n  st_transform(3857)\n\ntemplate &lt;- raster(polygons_proj, resolution = 25)\n\nraster_surface &lt;- fasterize(polygons_proj, template, field = \"test_id\", fun = \"sum\")\n\nraster_values &lt;- tibble(values = values(raster_surface)) %&gt;% \n  filter(!is.na(values)) %&gt;% \n  distinct(values) %&gt;% \n  pull(values)\n\nplot(raster_surface)"
  },
  {
    "objectID": "posts/healthy_ride_access_pittsburgh/index.html#build-interactive-map",
    "href": "posts/healthy_ride_access_pittsburgh/index.html#build-interactive-map",
    "title": "Bike rental access in Pittsburgh",
    "section": "Build interactive Map",
    "text": "Build interactive Map\nThis builds out the interactive map using leaflet and Mapbox libraries:\n\ncustom_pal &lt;- colorNumeric(\"viridis\", \n                           #0:max_bike_stations, \n                           raster_values,\n                           na.color = \"transparent\")\n\npopup_labels &lt;- sprintf(\"%s \n                        &lt;br&gt;Number of bike racks: %s\",\n                        stations$station_name, stations$number_of_racks) %&gt;% \n  map(htmltools::HTML)\n\nhealth_ride_icon &lt;- makeIcon(\n  iconUrl = \"https://healthyridepgh.com/wp-content/uploads/sites/3/2019/05/NEXTBIKE-LOGO-01.png\",\n  #iconUrl = \"https://healthyridepgh.com/wp-content/uploads/sites/3/2016/09/Healthy-Ride-Logo.Stacked-01.png\",\n  iconWidth = 50, iconHeight = 50,\n  iconAnchorX = 0, iconAnchorY = 0\n)\n\nstation_heatmap &lt;- mapbox_map %&gt;%\n  addPolygons(data = city_boundary,\n              opacity = 1,\n              color = \"black\",\n              fillColor = \"#ffffff\",\n              group = \"City boundary\") %&gt;% \n  addRasterImage(raster_surface, colors = custom_pal, opacity = .75,\n                 group = \"Raster\") %&gt;% \n  addLegend(pal = custom_pal, \n            values = raster_values,\n            title = \"Number of stations&lt;br&gt;within 10-minute bike ride\") %&gt;% \n  addMarkers(data = stations, lng = ~longitude, lat = ~latitude,\n             popup = popup_labels,\n             icon = health_ride_icon,\n             clusterOptions = markerClusterOptions(),\n             group = \"Stations\") %&gt;% \n  addLayersControl(overlayGroups = c(\"City boundary\", \"Raster\", \"Stations\"),\n                   options = layersControlOptions(collapsed = FALSE)) %&gt;% \n  addFullscreenControl() %&gt;% \n  setView(lng = pgh_coords[1], lat = pgh_coords[2], zoom = 12)\n\nframeWidget(station_heatmap, options=frameOptions(allowfullscreen = TRUE))"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/riverhounds_lilley/index.html",
    "href": "posts/riverhounds_lilley/index.html",
    "title": "Pittsburgh Riverhounds under Coach Lilley",
    "section": "",
    "text": "I have been a season-ticket holder with the Pittsburgh Riverhounds for a couple seasons now. The stadium has a great fan experience, and the team has gotten a lot better over the past few years. A major part of that is the head coach, Bob Lilley. I will use some data from American Soccer Analysis to show how the Riverhounds have improved. Their website has an explainer on expected goals and other metrics they calculate.\nLoad libraries and configure settings:\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(hrbrthemes)\nlibrary(ggrepel)\n\ntheme_set(theme_ipsum(base_size = 18))\n\n#source https://app.americansocceranalysis.com/#!/\n\nI pulled a CSV of team-level goal metrics for the last 4 USL seasons from the ASA website. This shows the available data:\n\nusl &lt;- read_csv(\"post_data/american_soccer_analysis_uslc_xgoals_teams_2023-10-15.csv\") %&gt;% \n  clean_names() %&gt;% \n  select(-x1) %&gt;% \n  mutate(coach = case_when(team == \"PIT\" & season &gt;= 2018 ~ \"Lilley\",\n                           team == \"PIT\" & season &lt; 2018 ~ \"Brandt\",\n                           TRUE ~ NA_character_)) |&gt; \n  filter(season &lt; 2021)\n\nglimpse(usl)\n\nRows: 134\nColumns: 15\n$ team    &lt;chr&gt; \"PHX\", \"CIN\", \"RNO\", \"LOU\", \"HFD\", \"PIT\", \"SLC\", \"SA\", \"TBR\", …\n$ season  &lt;dbl&gt; 2019, 2018, 2020, 2020, 2020, 2020, 2017, 2020, 2020, 2020, 20…\n$ games   &lt;dbl&gt; 34, 34, 16, 16, 16, 16, 32, 16, 16, 16, 34, 15, 16, 34, 34, 34…\n$ sht_f   &lt;dbl&gt; 16.79, 12.68, 16.06, 15.06, 10.31, 10.81, 11.88, 14.81, 12.63,…\n$ sht_a   &lt;dbl&gt; 13.32, 15.15, 14.94, 9.56, 12.19, 7.81, 11.41, 12.44, 9.38, 13…\n$ gf      &lt;dbl&gt; 2.53, 2.06, 2.69, 1.75, 1.88, 2.38, 1.84, 1.88, 1.56, 2.75, 1.…\n$ ga      &lt;dbl&gt; 1.00, 0.97, 1.31, 0.75, 1.44, 0.63, 0.91, 0.75, 0.63, 1.19, 0.…\n$ gd      &lt;dbl&gt; 1.53, 1.09, 1.38, 1.00, 0.44, 1.75, 0.94, 1.13, 0.94, 1.56, 0.…\n$ x_gf    &lt;dbl&gt; 2.08, 1.43, 2.25, 1.48, 1.32, 1.69, 1.46, 1.58, 1.63, 2.39, 1.…\n$ x_ga    &lt;dbl&gt; 1.37, 1.26, 1.53, 1.01, 1.35, 0.94, 1.34, 1.17, 0.84, 1.30, 0.…\n$ x_gd    &lt;dbl&gt; 0.71, 0.17, 0.72, 0.47, -0.03, 0.75, 0.12, 0.42, 0.79, 1.10, 0…\n$ gd_x_gd &lt;dbl&gt; 0.82, 0.92, 0.65, 0.53, 0.46, 1.00, 0.81, 0.71, 0.15, 0.47, 0.…\n$ pts     &lt;dbl&gt; 2.29, 2.26, 2.25, 2.19, 2.19, 2.13, 2.09, 2.06, 2.06, 2.00, 2.…\n$ x_pts   &lt;dbl&gt; 1.80, 1.49, 1.83, 1.70, 1.39, 1.86, 1.44, 1.64, 1.85, 1.98, 1.…\n$ coach   &lt;chr&gt; NA, NA, NA, NA, NA, \"Lilley\", NA, NA, NA, NA, \"Lilley\", NA, NA…\n\n\nThe Riverhound’s statistics show clear improvement in 2018 when Lilley took over from Brandt. The team immediately began scoring more than they allowed. The team’s expected goals for and against also improved, which shows that the improvement wasn’t a matter of luck.\n\ngoal_data &lt;- usl %&gt;% \n  filter(team == \"PIT\") %&gt;% \n  select(team, season, gf, x_gf, ga, x_ga) %&gt;% \n  pivot_longer(cols = c(gf, x_gf, ga, x_ga), names_to = \"g_type\", values_to = \"g_value\") %&gt;%\n  mutate(goal_type = case_when(str_detect(g_type, \"gf$\") ~ \"For\",\n                               TRUE ~ \"Against\")) %&gt;% \n  mutate(metric_type = case_when(str_detect(g_type, \"^x_\") ~ \"Expected\",\n                                 TRUE ~ \"Actual\"))\n\ngoal_data %&gt;% \n  ggplot(aes(season, g_value, color = goal_type, lty = metric_type)) +\n  geom_line(size = 1.5) +\n  geom_point(data = filter(goal_data, metric_type == \"Actual\"), size = 2) +\n  labs(title = \"Pittsburgh Riverhounds\",\n       subtitle = \"Expected and Actual Goals per game\",\n       x = \"Season\",\n       y = \"Goals\",\n       color = \"Goal Type\",\n       lty = \"Metric Type\")\n\n\n\n\nThis shows that in terms of expected goal difference, the Riverhounds became one of the top teams in the USL once Lilley took over.\n\nusl %&gt;% \n  ggplot(aes(season, x_gd, group = team)) +\n  geom_hline(yintercept = 0, size = 1, lty = 2) +\n  geom_line(color = \"black\", alpha = .2) +\n  geom_line(data = filter(usl, team == \"PIT\"), \n            color = \"gold\", size = 2) +\n  geom_point(data = filter(usl, team == \"PIT\"),\n             aes(fill = coach),\n             shape = 21, size = 4) +\n  scale_fill_manual(values = c(\"grey\", \"gold\")) +\n  #coord_fixed(ratio = .5) +\n  labs(title = \"xG difference per game\",\n       x = \"Season\",\n       y = \"xG Difference\",\n       fill = \"Riverhounds Coach\",\n       caption = \"Grey lines show other USL teams\")\n\n\n\n\nLilley’s Riverhounds are consistently better than league average in terms of expected goals.\n\nusl %&gt;% \n  ggplot(aes(x_gd)) +\n  #geom_histogram(binwidth = .2) +\n  geom_vline(data = filter(usl, team == \"PIT\"), aes(xintercept = x_gd), size = 3) +\n  geom_vline(data = filter(usl, team == \"PIT\"), aes(xintercept = x_gd, color = coach),\n             size = 2.5, key_glyph = \"rect\") +\n  geom_density(aes(y = ..count.. * .2), fill = \"white\", alpha = 1) +\n  geom_vline(xintercept = 0, lty = 2) +\n  geom_hline(yintercept = 0) +\n  scale_color_manual(values = c(\"grey\", \"gold\")) +\n  scale_x_continuous(expand = c(0,0)) +\n  scale_y_continuous(expand = c(0,0)) +\n  coord_cartesian(ylim = c(0, 25)) +\n  #coord_fixed(ratio = .1) +\n  labs(title = \"xG Difference Per Game\",\n       subtitle = \"Distribution of all USL teams 2017-2020\",\n       x = \"xG\",\n       y = \"Number of teams\",\n       color = \"Riverhounds Coach\") +\n  theme(legend.key = element_rect(color = \"black\"))\n\n\n\n\nWhile the 2020 Riverhounds were a very good team, they were not quite as good as their plain goals for/against would show. This graph shows that they were fortunate to do as well as they did (which, again, was very well).\n\nusl %&gt;% \n  mutate(logo = case_when(team == \"PIT\" ~ \"post_data/pit_logo.png\",\n                          TRUE ~ NA_character_)) %&gt;% \n  ggplot(aes(x_gd, gd)) +\n  geom_abline(lty = 2) +\n  geom_point(alpha = .3) +\n  ggimage::geom_image(aes(image = logo)) +\n  geom_label_repel(data = filter(usl, team == \"PIT\"),\n                   aes(label = season, fill = coach),\n                   force = 5,\n                   key_glyph = \"rect\") +\n  annotate(\"text\", label = \"Under-performing\",\n           x = .75, y = -1.5) +\n  annotate(\"text\", label = \"Over-performing\",\n           x = -1, y = 1.5) +\n  tune::coord_obs_pred() +\n  scale_fill_manual(values = c(\"grey\", \"gold\")) +\n  labs(title = \"Goal and xG difference per game\",\n       x = \"xG Difference\",\n       y = \"Goal Difference\",\n       fill = \"Riverhounds Coach\") +\n  theme(legend.key = element_rect(color = \"black\"))\n\n\n\n\nThis shows that the 2020 Riverhounds were probably one of the most fortunate teams in the league, in addition to being very good.\n\nusl %&gt;% \n  ggplot(aes(season, gd_x_gd, group = team)) +\n  geom_hline(yintercept = 0, lty = 2) +\n  geom_line(color = \"black\", alpha = .2) +\n  geom_line(data = filter(usl, team == \"PIT\"),\n            color = \"gold\", size = 2) +\n  geom_point(data = filter(usl, team == \"PIT\"),\n             aes(fill = coach, group = team),\n             shape = 21, size = 4, color = \"black\") +\n  scale_fill_manual(values = c(\"grey\", \"gold\")) +\n  coord_cartesian(ylim = c(-1.5, 1.5)) +\n  #coord_fixed(ratio = .5) +\n  labs(title = \"Goal difference - xG difference\",\n       subtitle = \"Per game\",\n       x = \"Season\",\n       y = substitute(paste(\"\" %&lt;-% \"\", \"Under-performing\", \"  |  \", \"Over-performing\", \"\" %-&gt;% \"\")),\n       fill = \"Riverhounds Coach\",\n       caption = \"Grey lines show other USL teams\")\n\n\n\n\nIn FiveThirtyEights’ Global Soccer Power Index, the Riverhounds will begin the 2021 season ranked around #460 out of 639 teams."
  },
  {
    "objectID": "posts/effect-of-geographic-resolution-on-ebirdst-abundance/index.html",
    "href": "posts/effect-of-geographic-resolution-on-ebirdst-abundance/index.html",
    "title": "Effect of Geographic Resolution on ebirdst Abundance",
    "section": "",
    "text": "While exploring some of the citizen science bird observation data available through ebirdst, I was confused by how to understand the calculation of ebirdst’s abundance metric.\nThe ebirdst documentation (?ebirdst::load_raster) defines abundance as:\nI had seen some weird results when trying to manually calculate abundance as occurrence * count. My initial attempt had aggregated the results by month.\nThe underlying problem is that abundance and count are the results of models, and are subject to model error. I also believe that the data outputted from load_raster lacks the necessary significant digits to accurately recreate abundance. Lowering the resolution or aggregating the data will exacerbate this issue.\nThis code loads my convenience function to retrieve a metric for a species at a given geographic resolution. This gets occurrence, count, and abundance for the Northern Cardinal at high (3 km), medium (9 km), and low resolutions (27 km). The function also crops the underlying raster data to Pennsylvania.\nlibrary(here)\nlibrary(hrbrthemes)\nlibrary(patchwork)\n\nsource(\"https://raw.githubusercontent.com/conorotompkins/ebird_shiny_app/main/scripts/functions/get_species_metric.R\")\n\ntheme_set(theme_ipsum())\n\nspecies_table &lt;- crossing(location = \"Pennsylvania\",\n                          species = c(\"Northern Cardinal\"),\n                          metric = c(\"occurrence\", \"count\", \"abundance\"),\n                          resolution = c(\"hr\", \"mr\", \"lr\"))\nspecies_table\n\n# A tibble: 9 × 4\n  location     species           metric     resolution\n  &lt;chr&gt;        &lt;chr&gt;             &lt;chr&gt;      &lt;chr&gt;     \n1 Pennsylvania Northern Cardinal abundance  hr        \n2 Pennsylvania Northern Cardinal abundance  lr        \n3 Pennsylvania Northern Cardinal abundance  mr        \n4 Pennsylvania Northern Cardinal count      hr        \n5 Pennsylvania Northern Cardinal count      lr        \n6 Pennsylvania Northern Cardinal count      mr        \n7 Pennsylvania Northern Cardinal occurrence hr        \n8 Pennsylvania Northern Cardinal occurrence lr        \n9 Pennsylvania Northern Cardinal occurrence mr\nspecies_metrics &lt;- species_table %&gt;% \n  mutate(data = pmap(list(location, species, metric, resolution), ~get_species_metric(..1, ..2, ..2, ..3, ..4))) %&gt;% \n  mutate(resolution = fct_relevel(resolution, c(\"hr\", \"mr\", \"lr\"))) %&gt;% \n  arrange(species, metric, resolution) |&gt; \n  unnest(data) %&gt;% \n  unnest(data)\nspecies_metrics\n\n# A tibble: 1,243,320 × 13\n   location species metric resolution family_common_name common_name metric_desc\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;              &lt;chr&gt;       &lt;chr&gt;      \n 1 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 2 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 3 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 4 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 5 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 6 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 7 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 8 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n 9 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n10 Pennsyl… Northe… abund… hr         Northern Cardinal  Northern C… abundance  \n# ℹ 1,243,310 more rows\n# ℹ 6 more variables: date &lt;date&gt;, value &lt;dbl&gt;, month &lt;chr&gt;, region &lt;chr&gt;,\n#   x &lt;dbl&gt;, y &lt;dbl&gt;\nThis unnests the data and recalculates abundance (abundance_test) and the difference between actual abundance and abundance_test.\nspecies_table_unnested &lt;- species_metrics %&gt;%\n  select(species, resolution, date, month, x, y, metric_desc, value) %&gt;% \n  pivot_wider(id_cols = c(species, resolution, date, month, x, y),\n              names_from = metric_desc,\n              values_from = value) %&gt;% \n  select(species, resolution, date, month, x, y, count, occurrence, abundance) %&gt;% \n  mutate(abundance_test = count * occurrence,\n         diff = abundance - abundance_test)\nGrouping by month to get to the county level changes the grain of the data so much that abundance_test undershoots abundance by 20%. This occurs at all resolutions.\nspecies_metrics %&gt;%\n  select(species, resolution, date, month, x, y, metric_desc, value) %&gt;% \n  pivot_wider(id_cols = c(species, resolution, date, month, x, y),\n              names_from = metric_desc,\n              values_from = value) %&gt;% \n  select(species, resolution, date, month, x, y, count, occurrence, abundance) %&gt;% \n  group_by(species, month, resolution) %&gt;% \n  summarize(occurrence = mean(occurrence, na.rm = T),\n            count = mean(count, na.rm = T),\n            abundance = mean(abundance, na.rm = T)) %&gt;% \n  ungroup() %&gt;% \n  mutate(abundance_test = count * occurrence,\n         diff = abundance - abundance_test) %&gt;% \n  ggplot(aes(abundance, abundance_test)) +\n  geom_abline() +\n  geom_point() +\n  facet_wrap(~resolution) +\n  tune::coord_obs_pred()\n\n`summarise()` has grouped output by 'species', 'month'. You can override using\nthe `.groups` argument.\nTotally un-aggregated, abundance_test closely resembles abundance, but degrades as resolution decreases.\nspecies_table_unnested %&gt;% \n  select(abundance, abundance_test, resolution) %&gt;% \n  drop_na() %&gt;% \n  ggplot(aes(abundance, abundance_test)) +\n  geom_density_2d_filled(contour_var = \"ndensity\") +\n  geom_abline(color = \"white\") +\n  facet_wrap(~resolution) +\n  tune::coord_obs_pred() +\n  coord_cartesian(xlim = c(0, 4),\n                  ylim = c(0, 4)) +\n  guides(fill = guide_colorsteps())\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\nAt lower resolutions, the difference is positively skewed, which means that abundance is higher than abundance_test.\nspecies_table_unnested %&gt;% \n  drop_na(diff) %&gt;% \n  ggplot(aes(diff)) +\n  geom_histogram() +\n  facet_wrap(~resolution, scale = \"free_y\", ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nAt the highest resolution, diff is heteroskedastic. At lower resolutions, there are patterns to the error.\nspecies_table_unnested %&gt;% \n  drop_na(occurrence, diff) %&gt;% \n  ggplot(aes(occurrence, diff)) +\n  geom_density_2d_filled(contour_var = \"ndensity\") +\n  facet_wrap(~resolution) + \n  scale_x_percent() +\n  guides(fill = guide_colorsteps())\nThis was a useful exercise for me to understand how the geographic resolution and other aggregation of the data can affect estimated metrics, specifically in the citizen science context."
  },
  {
    "objectID": "posts/effect-of-geographic-resolution-on-ebirdst-abundance/index.html#update",
    "href": "posts/effect-of-geographic-resolution-on-ebirdst-abundance/index.html#update",
    "title": "Effect of Geographic Resolution on ebirdst Abundance",
    "section": "Update",
    "text": "Update\nI made an issue on the ebirdst Github page and talked to one of the maintainers about their definitions of count and abundance. I now have a much stronger understanding of these variables.\nThe following code reproduces the graph I attached to the issue:\n\nlibrary(hrbrthemes)\ntheme_set(theme_ipsum())\n\nnorcar_table &lt;- crossing(location = \"Pennsylvania\",\n                         species = c(\"Northern Cardinal\"),\n                         metric = c(\"occurrence\", \"count\", \"abundance\"),\n                         resolution = c(\"hr\"))\n\n\nnorcar_metrics &lt;- norcar_table %&gt;% \n  mutate(data = pmap(list(location, species, metric, resolution), ~get_species_metric(..1, ..2, ..2, ..3, ..4))) %&gt;% \n  mutate(resolution = fct_relevel(resolution, c(\"hr\", \"mr\", \"lr\"))) %&gt;% \n  arrange(species, metric, resolution) %&gt;%\n  unnest(data) |&gt; \n  unnest(data)\n\n\nnorcar_metrics_wide &lt;- norcar_metrics %&gt;% \n  select(species, date, x, y, metric_desc, value) %&gt;% \n  pivot_wider(names_from = metric_desc,\n              values_from = value)\n\nplot_1 &lt;- norcar_metrics_wide %&gt;% \n  drop_na(occurrence, count) %&gt;% \n  ggplot(aes(occurrence, count)) +\n  geom_density_2d_filled(contour_var = \"ndensity\") +\n  scale_x_percent() +\n  guides(fill = \"none\") +\n  theme_bw()\n\nplot_2 &lt;- norcar_metrics_wide %&gt;% \n  drop_na() %&gt;% \n  ggplot(aes(occurrence, abundance)) +\n  geom_density_2d_filled(contour_var = \"ndensity\") +\n  scale_x_percent() +\n  guides(fill = \"none\") +\n  theme_bw()\n\nplot_3 &lt;- norcar_metrics_wide %&gt;%\n  drop_na() %&gt;% \n  ggplot(aes(count, abundance)) +\n  geom_density_2d_filled(contour_var = \"ndensity\") +\n  geom_abline() +\n  guides(fill = \"none\") +\n  theme_bw()\n\nlayout &lt;- \"\nAACC\nBBCC\n\"\n\nplot_1 + plot_2 + plot_3 + \n  plot_layout(guides = 'collect', design = layout) +\n  plot_annotation(title = \"Northern Cardinal in Pennsylvania\")"
  },
  {
    "objectID": "posts/effect-of-geographic-resolution-on-ebirdst-abundance/index.html#citations",
    "href": "posts/effect-of-geographic-resolution-on-ebirdst-abundance/index.html#citations",
    "title": "Effect of Geographic Resolution on ebirdst Abundance",
    "section": "Citations",
    "text": "Citations\nFink, D., T. Auer, A. Johnston, M. Strimas-Mackey, O. Robinson, S. Ligocki, W. Hochachka, C. Wood, I. Davies, M. Iliff, L. Seitz. 2020. eBird Status and Trends, Data Version: 2019; Released: 2020 Cornell Lab of Ornithology, Ithaca, New York. https://doi.org/10.2173/ebirdst.2019"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/shiny-venn-diagram/index.html",
    "href": "posts/shiny-venn-diagram/index.html",
    "title": "Making a Venn diagram in Shiny",
    "section": "",
    "text": "Introduction\nThis blog post is about making Venn diagrams work in Shiny, and the issues I ran into with shiny::nearPoints(). I show how this impacted my initial approach, and discuss the underlying issue.\nTLDR; shiny::nearPoints() doesn’t work with dataframes containing list-columns the way I expected\n\n\nBackground\nI have been working on a Shiny app that I will use to plan birdwatching trips. It uses the {ebirdst} package to pull abundance data for hundreds of species of birds in 27x27km tiles in North America. A major feature of the app will be the ability to compare how similar two areas (tiles) are. This compares the abundance for a species in a given tile in a given month. I wanted to include a Venn diagram that shows which species are exclusive to each tile. The user can click on the Venn diagram to see the species associated with each segment of the Venn diagram.\nThis involves making a venn diagram in ggplot2 and extracting the segment that the user clicks on with nearPoints(). This was more challenging than I had anticipated.\n\n\nVenn diagram data\nnearPoints() requires:\n\ndf: a data frame with x and y coordinates it can interpret\ncoordinfo: the user click coordinates as captured from the ui\n\nI use the ggVennDiagram package to make the venn diagram plot. This package uses ggplot2, but does a lot of pre-processing of the data beforehand. This made it difficult to get access to the df for nearPoints().\nThis is an example of a ggVennDiagram plot. It takes a list object, turns that into a dataframe, and then uses sf to draw the circles.\n\nlibrary(tidyverse)\nlibrary(ggVennDiagram)\n\ngenes &lt;- paste(\"gene\",1:100,sep=\"\")\nset.seed(20210419)\nx &lt;- list(A=sample(genes,30),\n          B=sample(genes,50))\n\nggVennDiagram(x)\n\n\n\n\nLooking under the hood of ggVennDiagram() shows the pre-processing steps:\n\nvenn &lt;- Venn(x)\ndata &lt;- process_data(venn)\n\nVenn() creates an object with slots representing the two sets A and B\n\nVenn(x)\n\nAn object of class \"Venn\"\nSlot \"sets\":\n$A\n [1] \"gene27\" \"gene76\" \"gene57\" \"gene33\" \"gene78\" \"gene39\" \"gene63\" \"gene41\"\n [9] \"gene66\" \"gene17\" \"gene16\" \"gene69\" \"gene75\" \"gene9\"  \"gene68\" \"gene3\" \n[17] \"gene34\" \"gene54\" \"gene19\" \"gene83\" \"gene2\"  \"gene40\" \"gene87\" \"gene60\"\n[25] \"gene61\" \"gene24\" \"gene44\" \"gene93\" \"gene53\" \"gene7\" \n\n$B\n [1] \"gene84\"  \"gene36\"  \"gene37\"  \"gene47\"  \"gene91\"  \"gene46\"  \"gene92\" \n [8] \"gene33\"  \"gene67\"  \"gene73\"  \"gene25\"  \"gene5\"   \"gene63\"  \"gene2\"  \n[15] \"gene83\"  \"gene56\"  \"gene77\"  \"gene10\"  \"gene12\"  \"gene95\"  \"gene76\" \n[22] \"gene53\"  \"gene99\"  \"gene19\"  \"gene31\"  \"gene86\"  \"gene80\"  \"gene65\" \n[29] \"gene48\"  \"gene100\" \"gene89\"  \"gene58\"  \"gene35\"  \"gene30\"  \"gene21\" \n[36] \"gene44\"  \"gene72\"  \"gene18\"  \"gene45\"  \"gene42\"  \"gene1\"   \"gene27\" \n[43] \"gene90\"  \"gene14\"  \"gene43\"  \"gene26\"  \"gene96\"  \"gene17\"  \"gene16\" \n[50] \"gene29\" \n\n\nSlot \"names\":\n[1] \"A\" \"B\"\n\n\nprocess_data() turns those slots into dataframes with sf columns representing the segment polygons.\n\nvenn &lt;- Venn(x)\nprocess_data(venn)\n\nAn object of class \"VennPlotData\"\nSlot \"setEdge\":\nSimple feature collection with 2 features and 5 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 125 ymin: 250 xmax: 875 ymax: 750\nCRS:           NA\n# A tibble: 2 × 6\n  id                                        geometry component item  count name \n  &lt;chr&gt;                                 &lt;LINESTRING&gt; &lt;chr&gt;     &lt;nam&gt; &lt;int&gt; &lt;chr&gt;\n1 1     (500 716, 493.065 720.007, 485.954 723.777,… setEdge   &lt;chr&gt;    30 A    \n2 2     (500 284, 506.935 279.998, 514.046 276.243,… setEdge   &lt;chr&gt;    50 B    \n\nSlot \"setLabel\":\nSimple feature collection with 2 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 250 ymin: 780 xmax: 750 ymax: 780\nCRS:           NA\n# A tibble: 2 × 4\n  id     geometry component name \n  &lt;chr&gt;   &lt;POINT&gt; &lt;chr&gt;     &lt;chr&gt;\n1 1     (250 780) setLabel  A    \n2 2     (750 780) setLabel  B    \n\nSlot \"region\":\nSimple feature collection with 3 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 125 ymin: 250 xmax: 875 ymax: 750\nCRS:           NA\n# A tibble: 3 × 6\n  id                                        geometry component item  count name \n  &lt;chr&gt;                                    &lt;POLYGON&gt; &lt;chr&gt;     &lt;lis&gt; &lt;int&gt; &lt;chr&gt;\n1 1     ((500 716, 492.317 711.329, 484.878 706.459… region    &lt;chr&gt;    19 A    \n2 2     ((500 284, 507.683 288.649, 515.122 293.497… region    &lt;chr&gt;    39 B    \n3 12    ((507.683 711.328, 515.122 706.458, 522.317… region    &lt;chr&gt;    11 A..B \n\n\nThe region slot is most important for my purposes. It contains the sf polygons for the segments and the distinct counts exclusive to each segment.\n\nprocess_data(venn) %&gt;% \n  .@region\n\nSimple feature collection with 3 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 125 ymin: 250 xmax: 875 ymax: 750\nCRS:           NA\n# A tibble: 3 × 6\n  id                                        geometry component item  count name \n  &lt;chr&gt;                                    &lt;POLYGON&gt; &lt;chr&gt;     &lt;lis&gt; &lt;int&gt; &lt;chr&gt;\n1 1     ((500 716, 492.317 711.329, 484.878 706.459… region    &lt;chr&gt;    19 A    \n2 2     ((500 284, 507.683 288.649, 515.122 293.497… region    &lt;chr&gt;    39 B    \n3 12    ((507.683 711.328, 515.122 706.458, 522.317… region    &lt;chr&gt;    11 A..B \n\nprocess_data(venn) %&gt;% \n  .@region %&gt;% \n  ggplot(aes(fill = name)) +\n  geom_sf()\n\n\n\n\nI thought using nearPoints() would be pretty easy once I intercepted the region object from the preprocessing steps. I was wrong.\n\n\nShiny app error\nThis basic Shiny app will reproduce the error that nearPoints() generates:\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(ggVennDiagram)\nlibrary(sf)\n\n#ui\nui &lt;- fluidPage(\n  \n  titlePanel(\"Shiny Venn Diagram\"),\n  \n  mainPanel(\n    plotOutput(\"venn_diagram\", click = \"plot_click\"),\n    tableOutput(\"venn_table\")\n  )\n)\n\ngenes &lt;- paste(\"gene\",1:1000,sep=\"\")\nset.seed(20210419)\nx &lt;- list(A=sample(genes,300),\n          B=sample(genes,525))\n\nvenn &lt;- Venn(x)\nvenn_data &lt;- process_data(venn)@region %&gt;% \n  mutate(centroid = st_point_on_surface(geometry),\n         x = map_dbl(centroid, 1),\n         y = map_dbl(centroid, 2)) %&gt;% \n  select(x, y, name, geometry)\n\n#server\nserver &lt;- function(input, output){\n  \n  output$venn_diagram &lt;- renderPlot({\n    \n    venn_data %&gt;% \n      ggplot(aes(x, y, fill = name, label = name)) +\n      geom_sf() +\n      geom_label()\n    \n  })\n  \n  output$venn_table &lt;- renderTable({\n    \n    req(input$plot_click)\n    \n    nearPoints(venn_data, #this is the issue\n               input$plot_click,\n               threshold = 100)\n    \n  })\n  \n}\n\nThis is the error:\n\nWarning: Error in &lt;-: number of items to replace is not a multiple of replacement length\n104: print.xtable\n98: transform\n97: func\n95: f\n94: Reduce\n85: do\n84: hybrid_chain\n83: renderFunc\n82: output$venn_table\n1: shiny::runApp\n\n\n\nThe fix\nWrapping the venn_data object in st_drop_geometry() drops the sf list-column and turns it back into a regular dataframe.\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(ggVennDiagram)\nlibrary(sf)\n\n#ui\nui &lt;- fluidPage(\n  \n  titlePanel(\"Shiny Venn Diagram\"),\n  \n  mainPanel(\n    plotOutput(\"venn_diagram\", click = \"plot_click\"),\n    tableOutput(\"venn_table\")\n  )\n)\n\ngenes &lt;- paste(\"gene\",1:1000,sep=\"\")\nset.seed(20210419)\nx &lt;- list(A=sample(genes,300),\n          B=sample(genes,525))\n\nvenn &lt;- Venn(x)\nvenn_data &lt;- process_data(venn)@region %&gt;% \n  mutate(centroid = st_point_on_surface(geometry),\n         x = map_dbl(centroid, 1),\n         y = map_dbl(centroid, 2)) %&gt;% \n  select(x, y, name, geometry)\n\n#server\nserver &lt;- function(input, output){\n  \n  output$venn_diagram &lt;- renderPlot({\n    \n    venn_data %&gt;% \n      ggplot(aes(x, y, fill = name, label = name)) +\n      geom_sf() +\n      geom_label()\n    \n  })\n  \n  output$venn_table &lt;- renderTable({\n    \n    req(input$plot_click)\n    \n    nearPoints(st_drop_geometry(venn_data), #the fix\n               input$plot_click,\n               threshold = 100)\n    \n  })\n  \n}\n\n\n\nWorking Shiny App\nThis is a working example of a Venn diagram in Shiny. input$plot_click captures the coordinates of the click and nearPoints() returns a dataframe of the information about the segment the user clicked on. The ID of the segment is in the name column."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ctompkins_quarto_blog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nSuburbanization of Allegheny County\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2022\n\n\nR package build\n\n\n\n\n\n\n  \n\n\n\n\nMaking a Venn diagram in Shiny\n\n\n\n\n\n\n\nshiny\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2022\n\n\nConor Tompkins\n\n\n\n\n\n\n  \n\n\n\n\nEffect of Geographic Resolution on ebirdst Abundance\n\n\n\n\n\n\n\nR\n\n\neBird\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2021\n\n\nConor Tompkins\n\n\n\n\n\n\n  \n\n\n\n\nPittsburgh Riverhounds under Coach Lilley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2021\n\n\n\n\n\n\n  \n\n\n\n\nDriving Alone vs. Public Transportation in Pittsburgh\n\n\nMapping commuter modes with bivariate discretized bins\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2021\n\n\n\n\n\n\n  \n\n\n\n\nHouse Price Estimator Dashboard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2021\n\n\n\n\n\n\n  \n\n\n\n\nBike rental access in Pittsburgh\n\n\n\n\n\n\n\nR\n\n\nPittsburgh\n\n\nHealthy Ride\n\n\nWPRDC\n\n\n\n\n\n\n\n\n\n\n\nDec 4, 2020\n\n\n\n\n\n\n  \n\n\n\n\nShifting political winds\n\n\nOr, drawing arrows on maps\n\n\n\n\nR\n\n\nPolitics\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2020\n\n\n\n\n\n\nNo matching items"
  }
]