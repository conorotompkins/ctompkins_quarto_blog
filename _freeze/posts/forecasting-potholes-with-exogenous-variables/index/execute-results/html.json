{
  "hash": "c9ce93bdfd0bab6815d5cbc9be952d18",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Forecasting potholes with exogenous variables\nauthor: Conor Tomkpins\ndate: '2023-10-31'\nslug: forecasting-potholes-with-exogenous-variables\ncategories: []\ntags: []\nsubtitle: ''\nsummary: ''\nauthors: []\nlastmod: '2023-10-31T19:24:54-04:00'\nfeatured: no\nimage: featured.png\nexecute: \n  echo: true\n  warning: false\n  message: false\neditor_options: \n  chunk_output_type: console\n---\n\n\n### Intro\n\nIn this post I will extend the modelling approach from the [previous post](https://ctompkins.netlify.app/post/forecasting-pittsburgh-potholes-with-fable/) with exogenous variables (variables not directly about the quantity being measured in the time series). These time series models will take into account the time series dynamics of the historical data **and** any relationship between pothole reports and weather. As I noted in the previous post, you can imagine a \"physics\" model of pothole creation driven by precipitation and the freeze/thaw cycle. These models will attempt to capture some of that process.\n\n### Set up packages and environment\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fpp3)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(future)\nlibrary(hrbrthemes)\nlibrary(GSODR)\nlibrary(tictoc)\n\ntheme_set(theme_ipsum())\n\nplan(multisession)\n\noptions(scipen = 999, digits = 4)\n```\n:::\n\n\n\nThis code reads in the pothole data used in the previous post, aggregates it by year + month, and turns it into a `tsibble`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#read in pothole data\npothole_data <- read_csv(\"post_data/wprdc_311.csv\") |> \n  clean_names() |> \n  filter(request_type == \"Potholes\") |> \n  mutate(created_yearmonth = yearmonth(created_on))\n\npothole_df <- pothole_data |> \n  group_by(created_yearmonth, request_type) |> \n  summarize(report_count = n()) |> \n  ungroup() |> \n  as_tsibble()\n\npothole_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 93 x 3 [1M]\n   created_yearmonth request_type report_count\n               <mth> <chr>               <int>\n 1          2015 Apr Potholes              906\n 2          2015 May Potholes             1493\n 3          2015 Jun Potholes             1236\n 4          2015 Jul Potholes             1288\n 5          2015 Aug Potholes              734\n 6          2015 Sep Potholes              526\n 7          2015 Oct Potholes              516\n 8          2015 Nov Potholes              890\n 9          2015 Dec Potholes              309\n10          2016 Jan Potholes              222\n# ℹ 83 more rows\n```\n\n\n:::\n:::\n\n\n\n### Weather data\n\nThis uses the [{GSODR}](https://cran.r-project.org/web/packages/GSODR/index.html) package to get daily weather data from the USA National Centers for Environmental Information ('NCEI'). Temperature is in Celsius and precipitation is in millimeters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(system.file(\"extdata\", \"isd_history.rda\", package = \"GSODR\"))\n\nweather_raw <- get_GSOD(years = c(2014:2023), station = \"725205-14762\") |> \n  as_tibble() |> \n  clean_names()\n\nweather_data <- weather_raw |> \n  select(stnid, name, date = yearmoda, min, temp, max, prcp)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(weather_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 3,601\nColumns: 7\n$ stnid <chr> \"725205-14762\", \"725205-14762\", \"725205-14762\", \"725205-14762\", …\n$ name  <chr> \"ALLEGHENY COUNTY AIRPORT\", \"ALLEGHENY COUNTY AIRPORT\", \"ALLEGHE…\n$ date  <date> 2014-01-01, 2014-01-02, 2014-01-03, 2014-01-04, 2014-01-05, 201…\n$ min   <dbl> -5.0, -6.1, -13.9, -13.9, -2.8, -18.3, -22.8, -22.8, -6.0, -6.1,…\n$ temp  <dbl> -1.7, -2.1, -10.7, -6.6, 2.6, -2.1, -19.9, -11.8, -3.3, 3.4, 9.8…\n$ max   <dbl> 3.3, 3.3, -0.6, 3.9, 8.9, 10.6, -16.0, -4.4, 1.1, 8.9, 13.0, 12.…\n$ prcp  <dbl> 0.00, 0.00, 3.56, 0.00, 0.00, 7.37, 6.86, 0.00, 0.00, 0.25, 0.00…\n```\n\n\n:::\n:::\n\n\n\nNext I summarize the data by year + month and calculate various lags for each variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_data <- weather_data |> \n  mutate(date_ym = yearmonth(date)) |> \n  group_by(date_ym) |> \n  summarize(temp_min_avg = mean(min),\n            temp_avg = mean(temp),\n            temp_max_avg = mean(max),\n            prcp_sum = sum(prcp, na.rm = TRUE)) |> #2023-07-30 is missing prcp\n  ungroup() |> \n  mutate(temp_diff = temp_max_avg - temp_min_avg) |> \n  mutate(across(c(temp_min_avg, temp_avg, temp_max_avg, temp_diff, prcp_sum), ~lag(.x, 1), .names = \"{.col}_lag1\")) |> \n  mutate(across(c(temp_min_avg, temp_avg, temp_max_avg, temp_diff, prcp_sum), ~lag(.x, 2), .names = \"{.col}_lag2\")) |> \n  mutate(across(c(temp_min_avg, temp_avg, temp_max_avg, temp_diff, prcp_sum), ~lag(.x, 3), .names = \"{.col}_lag3\")) |> \n  select(date_ym, contains(\"temp_avg\"), contains(\"min\"), contains(\"max\"), contains(\"diff\"), contains(\"prcp\"))\n\nglimpse(weather_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 119\nColumns: 21\n$ date_ym           <mth> 2014 Jan, 2014 Feb, 2014 Mar, 2014 Apr, 2014 May, 20…\n$ temp_avg          <dbl> -4.668, -2.504, 2.194, 12.100, 17.574, 22.097, 21.69…\n$ temp_avg_lag1     <dbl> NA, -4.668, -2.504, 2.194, 12.100, 17.574, 22.097, 2…\n$ temp_avg_lag2     <dbl> NA, NA, -4.668, -2.504, 2.194, 12.100, 17.574, 22.09…\n$ temp_avg_lag3     <dbl> NA, NA, NA, -4.668, -2.504, 2.194, 12.100, 17.574, 2…\n$ temp_min_avg      <dbl> -10.2935, -6.8643, -4.5258, 5.3300, 11.0806, 16.4833…\n$ temp_min_avg_lag1 <dbl> NA, -10.2935, -6.8643, -4.5258, 5.3300, 11.0806, 16.…\n$ temp_min_avg_lag2 <dbl> NA, NA, -10.2935, -6.8643, -4.5258, 5.3300, 11.0806,…\n$ temp_min_avg_lag3 <dbl> NA, NA, NA, -10.2935, -6.8643, -4.5258, 5.3300, 11.0…\n$ temp_max_avg      <dbl> 1.7903, 2.9250, 9.9032, 19.9033, 24.2419, 28.2500, 2…\n$ temp_max_avg_lag1 <dbl> NA, 1.7903, 2.9250, 9.9032, 19.9033, 24.2419, 28.250…\n$ temp_max_avg_lag2 <dbl> NA, NA, 1.7903, 2.9250, 9.9032, 19.9033, 24.2419, 28…\n$ temp_max_avg_lag3 <dbl> NA, NA, NA, 1.7903, 2.9250, 9.9032, 19.9033, 24.2419…\n$ temp_diff         <dbl> 12.084, 9.789, 14.429, 14.573, 13.161, 11.767, 11.59…\n$ temp_diff_lag1    <dbl> NA, 12.084, 9.789, 14.429, 14.573, 13.161, 11.767, 1…\n$ temp_diff_lag2    <dbl> NA, NA, 12.084, 9.789, 14.429, 14.573, 13.161, 11.76…\n$ temp_diff_lag3    <dbl> NA, NA, NA, 12.084, 9.789, 14.429, 14.573, 13.161, 1…\n$ prcp_sum          <dbl> 47.25, 58.41, 56.13, 91.42, 149.08, 120.39, 83.81, 1…\n$ prcp_sum_lag1     <dbl> NA, 47.25, 58.41, 56.13, 91.42, 149.08, 120.39, 83.8…\n$ prcp_sum_lag2     <dbl> NA, NA, 47.25, 58.41, 56.13, 91.42, 149.08, 120.39, …\n$ prcp_sum_lag3     <dbl> NA, NA, NA, 47.25, 58.41, 56.13, 91.42, 149.08, 120.…\n```\n\n\n:::\n:::\n\n\n\n##### Explore weather data\n\nThis shows average temperature, average minimum temperature, and average maximum temperature in Pittsburgh by year + month.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_data |> \n  ggplot(aes(date_ym, temp_avg)) +\n  geom_ribbon(aes(ymin = temp_min_avg, ymax = temp_max_avg), alpha = .3) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nThis shows the sum of precipitation by year + month over time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_data |> \n  ggplot(aes(date_ym, prcp_sum)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\nThis compares precipitation vs the minimum temperature (below freezing highlighted).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_data |> \n  mutate(year = as.factor(year(date_ym))) |> \n  ggplot(aes(temp_min_avg, prcp_sum)) +\n  geom_rect(aes(xmin = -Inf, xmax = 0, ymin = -Inf, ymax = Inf), color = \"grey\", alpha = .1) +\n  geom_point(aes(color = year)) +\n  geom_vline(xintercept = 0) +\n  facet_wrap(vars(year)) +\n  guides(color = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n2017 and 2018 appear to have slightly more precipitation in below freezing temperatures, but not significantly.\n\n##### Compare weather data and pothole reports\n\nNext I do some EDA to visualize any connection between reports of potholes in the \"current\" month and weather.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npothole_df <- pothole_df |> \n  left_join(weather_data, by = c(\"created_yearmonth\" = \"date_ym\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npothole_df |> \n  as_tibble() |> \n  select(report_count, contains(\"temp_avg\")) |> \n  pivot_longer(contains(\"temp\")) |> \n  ggplot(aes(value, report_count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(vars(name), scales = \"free\") +\n  labs(title = \"Pothole reports vs. the average temperature\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThere is some positive relationship between lower average temperatures in previous months and pothole reports. The \"current\" average temperature does not appear to be related.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npothole_df |> \n  as_tibble() |> \n  select(report_count, contains(\"temp_diff\")) |> \n  pivot_longer(contains(\"temp\")) |> \n  ggplot(aes(value, report_count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(vars(name), scales = \"free\") +\n  labs(title = \"Pothole reports vs. the temperature difference\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nThere is a weakly positive relationship between temperature difference in the current month and pothole reports. Longer lags develop a negative relationship.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npothole_df |> \n  as_tibble() |> \n  select(report_count, contains(\"min\")) |> \n  pivot_longer(contains(\"min\")) |> \n  ggplot(aes(value, report_count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(vars(name), scales = \"free\") +\n  labs(title = \"Pothole reports vs. the minimum temperature\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThere appears to be a positive relationship between lower minimum temperature in previous months and pothole reports.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npothole_df |> \n  as_tibble() |> \n  select(report_count, contains(\"max\")) |> \n  pivot_longer(contains(\"max\")) |> \n  ggplot(aes(value, report_count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(vars(name), scales = \"free\") +\n  labs(title = \"Pothole reports vs. the maximum temperature\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nThere is some positive relationship between lower maximum temperature in previous months and pothole reports.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npothole_df |> \n  as_tibble() |> \n  select(report_count, contains(\"prcp\")) |> \n  pivot_longer(contains(\"prcp\")) |> \n  ggplot(aes(value, report_count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(vars(name), scales = \"free\") +\n  labs(title = \"Pothole reports vs. precipitation\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nThere is a positive relationship between the total precipitation in the current month and pothole reports.\n\n### Cross-validate models\n\nNext I cross-validate models using various combinations of the weather data as exogenous variables. I also make benchmark models for comparison.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#cv\npothole_cv <- stretch_tsibble(pothole_df, .step = 1, .init = 24)\n\npothole_cv |> \n  count(.id)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 2\n     .id     n\n   <int> <int>\n 1     1    24\n 2     2    25\n 3     3    26\n 4     4    27\n 5     5    28\n 6     6    29\n 7     7    30\n 8     8    31\n 9     9    32\n10    10    33\n# ℹ 60 more rows\n```\n\n\n:::\n:::\n\n\n\nAs in the previous post, `report_count` is transformed with `log(x + 1)` to force the predictions to be positive.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nprogressr::with_progress(\n  \n  model_df_exo <- pothole_cv |> \n    model(ets = ETS(log(report_count + 1)),\n          ts_lm = TSLM(log(report_count + 1) ~ trend() + season()),\n          ts_lm_exo = TSLM(log(report_count + 1) ~ trend() + season() + temp_avg + temp_min_avg + temp_max_avg + prcp_sum),\n          ts_lm_exo_lag1 = TSLM(log(report_count + 1) ~ trend() + season() + temp_avg_lag1 + temp_min_avg_lag1 + temp_max_avg_lag1 + prcp_sum_lag1),\n          ts_lm_exo_lag2 = TSLM(log(report_count + 1) ~ trend() + season() + temp_avg_lag2 + temp_min_avg_lag2 + temp_max_avg_lag2 + prcp_sum_lag2),\n          ts_lm_exo_lag3 = TSLM(log(report_count + 1) ~ trend() + season() + temp_avg_lag3 + temp_min_avg_lag3 + temp_max_avg_lag3 + prcp_sum_lag3),\n          ts_lm_exo_custom = TSLM(log(report_count + 1) ~ trend() + season() + temp_avg_lag3 + temp_diff + temp_min_avg_lag3 + temp_max_avg_lag1 + prcp_sum),\n          arima = ARIMA(log(report_count + 1)),\n          arima_exo = ARIMA(log(report_count + 1) ~ temp_avg + temp_min_avg + temp_max_avg + prcp_sum),\n          arima_exo_lag1 = ARIMA(log(report_count + 1) ~ temp_avg_lag1 + temp_min_avg_lag1 + temp_max_avg_lag1 + prcp_sum_lag1),\n          arima_exo_lag2 = ARIMA(log(report_count + 1) ~ temp_avg_lag2 + temp_min_avg_lag2 + temp_max_avg_lag2 + prcp_sum_lag2),\n          arima_exo_lag3 = ARIMA(log(report_count + 1) ~ temp_avg_lag3 + temp_min_avg_lag3 + temp_max_avg_lag3 + prcp_sum_lag3),\n          arima_exo_custom = ARIMA(log(report_count + 1) ~ temp_avg_lag3 + temp_diff + temp_min_avg_lag3 + temp_max_avg_lag1 + prcp_sum)\n    )\n)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n376.773 sec elapsed\n```\n\n\n:::\n:::\n\n\nThe \"exo_custom\" models represent a naive guess at what combinations of weather variables are most related, based on the previous graphs. A more methodological meteorological approach would probably be much better.\n\nI use `new_data` to generate 12 new future observations for each CV `.id` and make a forecast for each `.id` and `.model`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhorizon_data <- new_data(pothole_cv, 12) |> \n  left_join(pothole_df)\n\nhorizon_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 840 x 24 [1M]\n# Key:       .id [70]\n   created_yearmonth   .id request_type report_count temp_avg temp_avg_lag1\n               <mth> <int> <chr>               <int>    <dbl>         <dbl>\n 1          2017 Apr     1 Potholes             1191    14.3           4.65\n 2          2017 May     1 Potholes             1088    15.8          14.3 \n 3          2017 Jun     1 Potholes              880    20.7          15.8 \n 4          2017 Jul     1 Potholes              801    22.9          20.7 \n 5          2017 Aug     1 Potholes              620    20.8          22.9 \n 6          2017 Sep     1 Potholes              369    18.9          20.8 \n 7          2017 Oct     1 Potholes              278    14.8          18.9 \n 8          2017 Nov     1 Potholes              207     5.82         14.8 \n 9          2017 Dec     1 Potholes              131    -1.24          5.82\n10          2018 Jan     1 Potholes             1995    -3.45         -1.24\n# ℹ 830 more rows\n# ℹ 18 more variables: temp_avg_lag2 <dbl>, temp_avg_lag3 <dbl>,\n#   temp_min_avg <dbl>, temp_min_avg_lag1 <dbl>, temp_min_avg_lag2 <dbl>,\n#   temp_min_avg_lag3 <dbl>, temp_max_avg <dbl>, temp_max_avg_lag1 <dbl>,\n#   temp_max_avg_lag2 <dbl>, temp_max_avg_lag3 <dbl>, temp_diff <dbl>,\n#   temp_diff_lag1 <dbl>, temp_diff_lag2 <dbl>, temp_diff_lag3 <dbl>,\n#   prcp_sum <dbl>, prcp_sum_lag1 <dbl>, prcp_sum_lag2 <dbl>, …\n```\n\n\n:::\n\n```{.r .cell-code}\npothole_fc_exo <- model_df_exo |> \n  forecast(horizon_data)\n```\n:::\n\n\n\n##### Compare accuracy\n\nThis code calculates the out of sample accuracy for each `.id` and `.model`, and then averages the accuracy by `.model`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfc_exo_acc <- pothole_fc_exo |> \n  accuracy(pothole_df, measures = list(point_accuracy_measures, distribution_accuracy_measures, skill_crps = skill_score(CRPS))) |> \n  select(.model, .type, RMSE, skill_crps) |> \n  arrange(desc(skill_crps))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n7108.297 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nfc_exo_acc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 4\n   .model           .type  RMSE skill_crps\n   <chr>            <chr> <dbl>      <dbl>\n 1 arima_exo_custom Test   610.      0.743\n 2 arima_exo_lag3   Test   596.      0.741\n 3 ts_lm_exo_custom Test   658.      0.728\n 4 arima_exo_lag2   Test   658.      0.710\n 5 arima_exo_lag1   Test   660.      0.707\n 6 ts_lm_exo_lag3   Test   711.      0.699\n 7 arima_exo        Test   713.      0.696\n 8 ts_lm_exo_lag1   Test   758.      0.696\n 9 ts_lm            Test   780.      0.672\n10 ts_lm_exo_lag2   Test   875.      0.669\n11 ts_lm_exo        Test   793.      0.669\n12 ets              Test  1901.      0.540\n13 arima            Test  1843.      0.516\n```\n\n\n:::\n:::\n\n\n\nMy `arima_exo_custom` model slightly improves on the `arima_exo_lag3` model. \n\nExcluding the worst two models:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_exo_acc |> \n  filter(!.model %in% c(\"ets\", \"arima\")) |> \n  ggplot(aes(RMSE, skill_crps, label = .model)) +\n  geom_point() +\n  ggrepel::geom_label_repel(max.overlaps = 100) +\n  scale_x_reverse()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n### Scenario forecasting\n\nThis code simulates high and low scenarios of precipitation. I use these to create scenario forecasts based on varying levels of future precipitation and the temperature data. Then I forecast each scenario with the `arima_exo_custom` model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#extracts the 10%, 50%, and 90% percentiles of precipitation by month\nprcp_percentiles <- pothole_df |> \n  mutate(month = month(created_yearmonth, label = TRUE)) |> \n  as_tibble() |> \n  select(month, prcp_sum) |> \n  group_by(month) |> \n  reframe(pctiles = c(\"10\", \"50\", \"90\"),\n          prcp_sum = quantile(prcp_sum, probs = c(.1, .5, .9))) |> \n  ungroup() |> \n  pivot_wider(names_from = pctiles, values_from = prcp_sum, names_prefix = \"prcp_sum_\")\n\nprcp_percentiles\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 4\n   month prcp_sum_10 prcp_sum_50 prcp_sum_90\n   <ord>       <dbl>       <dbl>       <dbl>\n 1 Jan          46.0        86.8        104.\n 2 Feb          57.1        94.2        150.\n 3 Mar          57.6        74.7        124.\n 4 Apr          63.8       106.         125.\n 5 May          72.1       135.         159.\n 6 Jun          56.5       149.         277.\n 7 Jul          70.9       118.         193.\n 8 Aug          91.4       117.         155.\n 9 Sep          39.5        69.3        200.\n10 Oct          79         113.         131.\n11 Nov          21.4        65.5        105.\n12 Dec          46.2        93.3        120.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_horizon_data <- function(x, prcp_scenario, prcp_col){\n  \n  #drop the lagged weather variables from the input df containing historical weather data\n  x <- x |> \n    select(-contains(\"lag\"))\n  \n  #create a new dataframe with the next 12 future observations\n  new_df <- new_data(x, 12) |> \n    mutate(request_type = \"Potholes\")\n  \n  #find the monthly average for all the temperature variables\n  new_temp_data <- x |> \n    mutate(month = month(created_yearmonth, label = TRUE)) |> \n    as_tibble() |> \n    select(-contains(c(\"lag\", \"prcp\"))) |> \n    group_by(month) |> \n    summarize(across(where(is.numeric), mean)) |> \n    ungroup() |> \n    #add in percentile precipitation column\n    left_join(prcp_scenario |> \n                select(month, {{ prcp_col }})) |> \n    rename(prcp_sum = {{ prcp_col }})\n  \n  #join new temperature data\n  new_df <- new_df |> \n    mutate(month = month(created_yearmonth, label = TRUE)) |> \n    left_join(new_temp_data)\n\n  #append new temperature data to historical data\n  x <- x |> \n    bind_rows(new_df)\n\n  #recalculate the lagged weather data based on the given percentile of precipitation\n  x |>\n    mutate(across(c(temp_min_avg, temp_avg, temp_max_avg, temp_diff, prcp_sum), ~lag(.x, 1), .names = \"{.col}_lag1\")) |>\n    mutate(across(c(temp_min_avg, temp_avg, temp_max_avg, temp_diff, prcp_sum), ~lag(.x, 2), .names = \"{.col}_lag2\")) |>\n    mutate(across(c(temp_min_avg, temp_avg, temp_max_avg, temp_diff, prcp_sum), ~lag(.x, 3), .names = \"{.col}_lag3\")) |>\n    semi_join(new_df, by = c(\"created_yearmonth\")) |> \n    select(created_yearmonth, request_type, report_count, contains(\"temp_avg\"), contains(\"min\"), contains(\"max\"), contains(\"diff\"), contains(\"prcp\"))\n  \n}\n```\n:::\n\n\n\nThis shows the future scenario with 10th percentile precipitation in each month:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_horizon_data(pothole_df, prcp_percentiles, prcp_sum_10) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 12\nColumns: 23\n$ created_yearmonth <mth> 2023 Jan, 2023 Feb, 2023 Mar, 2023 Apr, 2023 May, 20…\n$ request_type      <chr> \"Potholes\", \"Potholes\", \"Potholes\", \"Potholes\", \"Pot…\n$ report_count      <dbl> 618.0, 1323.6, 1149.4, 1140.5, 1137.5, 874.4, 755.5,…\n$ temp_avg          <dbl> -1.001, 1.834, 5.820, 10.916, 17.100, 21.095, 23.503…\n$ temp_avg_lag1     <dbl> 1.887, -1.001, 1.834, 5.820, 10.916, 17.100, 21.095,…\n$ temp_avg_lag2     <dbl> 8.017, 1.887, -1.001, 1.834, 5.820, 10.916, 17.100, …\n$ temp_avg_lag3     <dbl> 11.287, 8.017, 1.887, -1.001, 1.834, 5.820, 10.916, …\n$ temp_min_avg      <dbl> -5.62304, -3.39310, 0.08664, 4.54833, 11.10927, 15.1…\n$ temp_min_avg_lag1 <dbl> -3.29032, -5.62304, -3.39310, 0.08664, 4.54833, 11.1…\n$ temp_min_avg_lag2 <dbl> 2.56333, -3.29032, -5.62304, -3.39310, 0.08664, 4.54…\n$ temp_min_avg_lag3 <dbl> 4.95161, 2.56333, -3.29032, -5.62304, -3.39310, 0.08…\n$ temp_max_avg      <dbl> 4.404, 7.953, 12.976, 18.346, 23.937, 27.482, 29.685…\n$ temp_max_avg_lag1 <dbl> 6.545, 4.404, 7.953, 12.976, 18.346, 23.937, 27.482,…\n$ temp_max_avg_lag2 <dbl> 13.753, 6.545, 4.404, 7.953, 12.976, 18.346, 23.937,…\n$ temp_max_avg_lag3 <dbl> 17.977, 13.753, 6.545, 4.404, 7.953, 12.976, 18.346,…\n$ temp_diff         <dbl> 10.027, 11.346, 12.889, 13.798, 12.827, 12.326, 11.7…\n$ temp_diff_lag1    <dbl> 9.835, 10.027, 11.346, 12.889, 13.798, 12.827, 12.32…\n$ temp_diff_lag2    <dbl> 11.190, 9.835, 10.027, 11.346, 12.889, 13.798, 12.82…\n$ temp_diff_lag3    <dbl> 13.026, 11.190, 9.835, 10.027, 11.346, 12.889, 13.79…\n$ prcp_sum          <dbl> 46.02, 57.14, 57.64, 63.77, 72.06, 56.53, 70.94, 91.…\n$ prcp_sum_lag1     <dbl> 50.28, 46.02, 57.14, 57.64, 63.77, 72.06, 56.53, 70.…\n$ prcp_sum_lag2     <dbl> 99.30, 50.28, 46.02, 57.14, 57.64, 63.77, 72.06, 56.…\n$ prcp_sum_lag3     <dbl> 66.54, 99.30, 50.28, 46.02, 57.14, 57.64, 63.77, 72.…\n```\n\n\n:::\n:::\n\n\n\nNext I create the scenarios to be fed into the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create scenarios\nfc_scenarios <- scenarios(\n  \n  scenario_low = create_horizon_data(pothole_df, prcp_percentiles, prcp_sum_10),\n  \n  scenario_median = create_horizon_data(pothole_df, prcp_percentiles, prcp_sum_50),\n  \n  scenario_high = create_horizon_data(pothole_df, prcp_percentiles, prcp_sum_90)\n  \n)\n\nstr(fc_scenarios, max.level = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 3\n $ scenario_low   : tbl_ts [12 × 23] (S3: tbl_ts/tbl_df/tbl/data.frame)\n  ..- attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n  ..- attr(*, \"index\")= chr \"created_yearmonth\"\n  .. ..- attr(*, \"ordered\")= logi TRUE\n  ..- attr(*, \"index2\")= chr \"created_yearmonth\"\n  ..- attr(*, \"interval\")= interval [1:1] 1M\n $ scenario_median: tbl_ts [12 × 23] (S3: tbl_ts/tbl_df/tbl/data.frame)\n  ..- attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n  ..- attr(*, \"index\")= chr \"created_yearmonth\"\n  .. ..- attr(*, \"ordered\")= logi TRUE\n  ..- attr(*, \"index2\")= chr \"created_yearmonth\"\n  ..- attr(*, \"interval\")= interval [1:1] 1M\n $ scenario_high  : tbl_ts [12 × 23] (S3: tbl_ts/tbl_df/tbl/data.frame)\n  ..- attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n  ..- attr(*, \"index\")= chr \"created_yearmonth\"\n  .. ..- attr(*, \"ordered\")= logi TRUE\n  ..- attr(*, \"index2\")= chr \"created_yearmonth\"\n  ..- attr(*, \"interval\")= interval [1:1] 1M\n - attr(*, \"names_to\")= chr \".scenario\"\n```\n\n\n:::\n:::\n\n\n\nThis shows the monthly precipitation in each scenario:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_scenarios |> \n  map(as_tibble) |> \n  set_names(nm = c(\"scenario_low\", \"scenario_median\", \"scenario_high\")) |> \n  bind_rows(.id = \".scenario\") |> \n  select(.scenario, created_yearmonth, prcp_sum) |> \n  mutate(.scenario = as.factor(.scenario)) |> \n  ggplot(aes(created_yearmonth, prcp_sum, color = .scenario)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\nFinally, I refit the model against the entire history and forecast against each scenario.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#refit best model on total history\nfinal_exo_model <- pothole_df |> \n  model(arima_exo_custom = ARIMA(log(report_count + 1) ~ temp_avg_lag3 + temp_diff + temp_min_avg_lag3 + temp_max_avg_lag1 + prcp_sum))\n\nreport(final_exo_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: report_count \nModel: LM w/ ARIMA(0,1,1) errors \nTransformation: log(report_count + 1) \n\nCoefficients:\n          ma1  temp_avg_lag3  temp_diff  temp_min_avg_lag3  temp_max_avg_lag1\n      -0.6696         0.1409     0.1378            -0.1879            -0.0131\ns.e.   0.0895         0.0716     0.0378             0.0718             0.0072\n      prcp_sum\n        0.0025\ns.e.    0.0009\n\nsigma^2 estimated as 0.2233:  log likelihood=-58.77\nAIC=131.5   AICc=132.9   BIC=149.2\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#forecast scenarios\nscenerio_fc <- final_exo_model |> \n  forecast(fc_scenarios) |> \n  mutate(.scenario = fct_relevel(.scenario, c(\"scenario_low\", \"scenario_median\", \"scenario_high\")))\n\nscenerio_fc |> \n  mutate(.scenario = fct_rev(.scenario)) |> \n  autoplot() +\n  facet_wrap(vars(.scenario), scales = \"fixed\", ncol = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/forecast_scenarios-1.png){width=672}\n:::\n:::\n\n\n\nThe model predicts that the scenario with more precipitation will have ~1,000 more pothole reports in the next 12 months than the scenario with less precipitation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscenerio_fc |> \n  as_tibble() |> \n  group_by(.scenario) |> \n  summarize(total_pothole_fc = sum(.mean)) |> \n  ggplot(aes(total_pothole_fc, .scenario)) +\n  geom_col() +\n  scale_x_comma()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] tictoc_1.2.1      GSODR_4.1.3       hrbrthemes_0.8.7  future_1.34.0    \n [5] janitor_2.2.0     forcats_1.0.0     stringr_1.5.1     purrr_1.0.2      \n [9] readr_2.1.5       tidyverse_2.0.0   fable_0.4.1       feasts_0.4.1     \n[13] fabletools_0.5.0  tsibbledata_0.4.1 tsibble_1.1.5     ggplot2_3.5.1    \n[17] lubridate_1.9.3   tidyr_1.3.1       dplyr_1.1.4       tibble_3.2.1     \n[21] fpp3_1.0.1       \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1        farver_2.1.2            fastmap_1.2.0          \n [4] fontquiver_0.2.1        digest_0.6.37           timechange_0.3.0       \n [7] lifecycle_1.0.4         ellipsis_0.3.2          magrittr_2.0.3         \n[10] compiler_4.4.1          rlang_1.1.4             tools_4.4.1            \n[13] utf8_1.2.4              yaml_2.3.10             data.table_1.16.0      \n[16] knitr_1.48              labeling_0.4.3          htmlwidgets_1.6.4      \n[19] bit_4.0.5               numDeriv_2016.8-1.1     withr_3.0.1            \n[22] grid_4.4.1              fansi_1.0.6             gdtools_0.4.0          \n[25] colorspace_2.1-1        progressr_0.14.0        extrafontdb_1.0        \n[28] globals_0.16.3          scales_1.3.0            cli_3.6.3              \n[31] anytime_0.3.9           rmarkdown_2.28          crayon_1.5.3           \n[34] generics_0.1.3          future.apply_1.11.2     rstudioapi_0.16.0      \n[37] tzdb_0.4.0              splines_4.4.1           parallel_4.4.1         \n[40] vctrs_0.6.5             Matrix_1.7-0            jsonlite_1.8.8         \n[43] fontBitstreamVera_0.1.1 hms_1.1.3               ggrepel_0.9.6          \n[46] bit64_4.0.5             listenv_0.9.1           systemfonts_1.1.0      \n[49] ggdist_3.3.2            glue_1.8.0              parallelly_1.38.0      \n[52] codetools_0.2-20        distributional_0.5.0    stringi_1.8.4          \n[55] gtable_0.3.5            extrafont_0.19          munsell_0.5.1          \n[58] pillar_1.9.0            rappdirs_0.3.3          htmltools_0.5.8.1      \n[61] R6_2.5.1                vroom_1.6.5             evaluate_0.24.0        \n[64] lattice_0.22-6          snakecase_0.11.1        renv_1.0.11            \n[67] fontLiberation_0.1.0    Rcpp_1.0.13             nlme_3.1-164           \n[70] Rttf2pt1_1.3.12         mgcv_1.9-1              xfun_0.49              \n[73] pkgconfig_2.0.3        \n```\n\n\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}